--- 
title: "Dana analysis script"
author: "Ibana Matsuo"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
csl: apa.csl
# url: your book url like https://bookdown.org/yihui/bookdown
# cover-image: path to the social sharing image like images/cover.jpg
description: |
  This is a minimal example of using the bookdown package to write a book.
  The HTML output format for this example is bookdown::gitbook,
  set in the _output.yml file.
link-citations: yes
github-repo: imatsuo/emotion-effect-bilingual-reading
---

# Overview

This webpage consists of the R script I used to conduct data cleaning, wrangling, visualisation, and statistical analysis for my MSc Dissertation project at the University of Glasgow.

**Dissertation Title:** The Emotion Effect in First- and Second- Language Book Reading: Emotional Disembodiment or Attentional Advantage?

**Abstract**  
Bilinguals’ emotion processing has emerged as an exciting area of research given the ubiquitous nature of bilingualism and the importance of language in emotion processing. Despite a growing consensus that written words are processed differently depending on their emotional valence, existing research on emotion and lexical processing has mostly been conducted with a single-word experimental paradigm. The present study analysed data from a bilingual corpus of eye movements while reading a novel to investigate processing differences among three valence categories (positive/negative/neutral) and between bilinguals’ L1 and L2 (Dutch/English). We found no processing differences among the valence categories in L1, which is contrary to the previous studies. Interestingly, the only processing advantage we found was in L2 positive words over neutral words. These findings suggest that valence may not exert a processing advantage when bilinguals read in L1, and that the disembodiment account of L2   may not explain the processing patterns in L2. The implications of these findings are discussed with a model of emotion and attentional resources and the emotionality of global narrative contexts, instead of individual words. 

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

<!--chapter:end:index.Rmd-->

---
editor_options: 
  markdown: 
    wrap: 72
---

# Set-up and Data preparation

## Load libraries

```{r warning=FALSE, message =FALSE}
library("readxl")
library("lme4")
library("emmeans")
library("broom.mixed")
library("kableExtra")
library("tidyverse")
library("optimx") #optimx package for modelling
```

## Prepare GECO Material

GECO Materials are downloaded from [@cop2016]
<https://expsy.ugent.be/downloads/geco/>

```{r}
EnglishMaterial_raw <- read_excel("EnglishMaterial.xlsx")
DutchMaterial_raw <- read_excel("DutchMaterials.xlsx")
```

I created Material tibbles (EnglishMaterial & DutchMaterial) by only
selecting necessary columns (Language, WORD_ID, WORD, PART_OF_SPEECH,
CONTENT_WORD, WORD_LENGTH) and only content words.

```{r}
EnglishMaterial <- EnglishMaterial_raw %>%
  mutate(Language = "English") %>%
  select(Language, WORD_ID, WORD, PART_OF_SPEECH, CONTENT_WORD, WORD_LENGTH) %>%
  filter(CONTENT_WORD == "1") %>% 
  unique()

DutchMaterial <- DutchMaterial_raw %>%
  mutate(Language = "Dutch",
         WORD_ID = IA_ID) %>%
  select(Language, WORD_ID, WORD, PART_OF_SPEECH, CONTENT_WORD, WORD_LENGTH) %>%
  filter(CONTENT_WORD == "1") %>%
  unique()
```

## Prepare Valence dataset

Valence rating datasets are downloaded from
<http://crr.ugent.be/programs-data/word-ratings>. Because two valence
datasets use different rating metrics, I transformed valence ratings
(V_Mean) to V_Mean_percent, ranging 0-1. close to 0 is negative, and
close to 1 is positive.

**English**\
Original rating by [@warriner2013] is 1(happy) - 9(unhappy). The valence
rating are already reversed post-hoc to maintain more intuitive
low-to-high scale 1(unhappy) - 9(happy) (5 = neutral). Thus no need to
reverse again.

```{r}
EnglishValence <- read.csv("Ratings_Warriner_et_al.csv")
```

In this dataset, Percent_known not collected. Number of contribution is
stored as V.Rat.Sum in original dataset.

```{r}
EnglishValence <- EnglishValence %>%
  select(Word, V.Mean.Sum, V.SD.Sum) %>%
    rename(WORD = Word,
         V_Mean = V.Mean.Sum,
         V_SD = V.SD.Sum) %>%
  mutate(V_Mean_Percent = (V_Mean-1)/(9-1))
```

**Dutch**\
Original rating by [@moors2012] is 1(unhappy) - 7(happy) (4 = neutral).

```{r warning = FALSE, message=FALSE}
DutchValence <- read_excel("WordNorms Moors et al.xlsx", skip = 1)


DutchValence <- DutchValence %>%
  select(Words, Translation, 'M V...3', 'SD V...4', 'N (%)') %>%
  rename(WORD = Words,
         V_Mean = 'M V...3',
         V_SD = 'SD V...4',
         UnknownRatio = 'N (%)') %>%
  mutate(V_Percent_known = (100 - UnknownRatio)/100,
         V_Mean_Percent = (V_Mean-1)/(7-1))
```

For DutchWords, we will remove any words which scores more than 30 on
UnknownRatio c.f., less than 70% of participants knew the words The max
of UnknownRation is zweem's 26.9%, therefore include all words in
analysis.

## Prepare concreteness rating

Two published concreteness ratings [@brysbaert2014 for Dutch;
@brysbaert2013 for English] are used to include in a model as a control
variable.

**English**

```{r}
EnglishConcreteness <- read_excel("Concreteness_ratings_Brysbaert_et_al_BRM.xlsx") 

EnglishConcreteness <- EnglishConcreteness %>%
  select(Word, Bigram, Conc.M, Conc.SD, Percent_known) %>%
  rename(WORD = Word,
         Conc_Mean = Conc.M,
         Conc_SD = Conc.SD,
         C_Percent_known = Percent_known) %>%
  filter(Bigram == "0") %>% #filter out two-word expressions (2896 out of 39954 words)
  select(-Bigram)
```

**Dutch**\
read_excel() returned warning, thus I converted the excel file into csv
file and used read_csv() function.

```{r message=FALSE}
DutchConcreteness <- read_csv("Concreteness ratings Brysbaert et al.csv")

DutchConcreteness <- DutchConcreteness %>%
  select(stimulus, Concrete_m, Concrete_sd, `Number_of_ratings`, Number_of_subjects) %>%
  mutate(C_Percent_known = `Number_of_ratings`/ Number_of_subjects) %>%
  select(stimulus, Concrete_m, Concrete_sd, C_Percent_known) %>%
  rename(WORD = stimulus,
         Conc_Mean = Concrete_m,
         Conc_SD = Concrete_sd)
```

In the original Dutch dataset, I found that there are 17 duplicate Dutch
words with different concreteness ratings, making the number of words to
30070.

```{r}
DutchConcreteness_dup <- DutchConcreteness %>%
  subset(duplicated(WORD)) %>%
  select(WORD) %>%
  unique() %>%
  mutate(Duplicate = "1") #1 means Yes

DutchConcreteness_dup2 <- left_join(DutchConcreteness, DutchConcreteness_dup, "WORD") %>%
  mutate(Duplicate = replace_na(Duplicate, "0")) %>%
  filter(Duplicate == "1")

```

Now DutchConcreteness_dup contains 73 duplicate rows. Here are the steps
I followed: 1) calculate the Conc_M means of each duplicate word, 2)
make a list of 17 words with the mean Conc_M, then 3) replace it into
final DutchConcreteness dataset.

```{r}
#1) calculate Mean of Conc_Mean for each duplicate word
DutchConcreteness_dup2 <- DutchConcreteness_dup2 %>%
  group_by(WORD) %>%
  mutate(Conc_Mean_M = mean(Conc_Mean)) %>%
  ungroup()
  
#2) make a list of 17 words
DutchConcreteness_dup2 <- DutchConcreteness_dup2 %>%
  select(WORD, Conc_Mean_M) %>%
  unique() %>%
  rename(Conc_Mean = Conc_Mean_M) %>%
  # add back Conc_SD and C_Percent_known columns to match up with the DutchConcreteness dataset
  mutate(Conc_SD = 1,
         C_Percent_known = 1,
         Duplicate = "0") #0 means No

#3) Replace it into final DutchConcreteness dataset
DutchConcreteness_F <- left_join(DutchConcreteness, DutchConcreteness_dup, "WORD") %>%
  mutate(Duplicate = replace_na(Duplicate, "0")) %>%
  filter(Duplicate == "0") #0 means No

#29997 words

```

29997+17=30014 words in the final tibble named DutchConcreteness.

```{r}
DutchConcreteness <- bind_rows(DutchConcreteness_F, DutchConcreteness_dup2) %>%
  select(-Duplicate)
```

## Prepare list of Identical cognates

We decided to exclude identical cognates as research shows that cognates
are recognised and processed faster [i.e., cognates effect;
@dijkstra2010a]. Data is retrieved from @poort2019
(<https://osf.io/tcdxb/>).

```{r}
DutchEnglishCognates <- read_excel("PoortRodd.DatabaseOf58IdenticalCognates76Non-IdenticalCognates72InterlingualHomographs78TranslationEquivalents.xlsx", 'identical cognates')

DutchEnglishCognates <- DutchEnglishCognates %>%
  select(word_NL, word_EN) %>%
  mutate(WORD = word_EN,
         Cognate = "1") %>% # 1 means Yes
  select(WORD, Cognate)
```

## Combine prepared datasets to create target word lists

**English**\
I used inner_join() to combine English Material, Valence
rating(independent variable), and concreteness rating(control variable).
Then I used left_join() to add information of cognates.

```{r}
EnglishMaterialValence <- inner_join(EnglishMaterial, EnglishValence, "WORD")
EnglishMaterialValConc <- inner_join(EnglishMaterialValence, EnglishConcreteness, "WORD")

##Cognates
EnglishWordList_w_Cognate <- left_join(EnglishMaterialValConc, DutchEnglishCognates, "WORD")
#EnglishCognateList <- EnglishWordList_w_Cognate %>%
#  filter(Cognate == "1")
#23 out of 2200 words are cognates to remove

```

To determine whether I use inner_join() or left_join() to combine
concreteness rating (control variable), I checked the number of words
with no concreteness rating. With the below coding I found that only 24
out of 2224 words do not have concreteness rating, thus removing them
would not affect the quality of final word list.

```{r}
#EnglishMaterialValenceConcreteness <- left_join(EnglishMaterialValence, EnglishConcreteness, "WORD")
#24 out of 2224 words do not have concreteness rating -> removing them would not affect the final word list
```

Finally, I create EnglishWordList tibble by removing cognates.

```{r}
EnglishWordList <- EnglishWordList_w_Cognate %>%
  replace(is.na(.),"0") %>%
  filter(Cognate == "0")
```

**Dutch**\
Same as English, I checked the number of words with no concreteness
rating to decide whether I use innter_join() or left_join() to add
concreteness rating. With the below coding I found that 8 out of 1294
words do not have concreteness rating, thus removing them would not
affect the quality of final word list.

```{r eval=FALSE}
DutchMaterialValenceConcreteness <- left_join(DutchMaterialValence, DutchConcreteness, "WORD")
#8 out of 1294 words do not have concreteness rating -> removing them would not affect the final word list
```

The below codes shows how I combined DutchMaterial, Valence
rating(independent variable), and concreteness rating(control variable).

```{r}
DutchMaterialValence <- inner_join(DutchMaterial, DutchValence, "WORD")
DutchMaterialValConc <- inner_join(DutchMaterialValence, DutchConcreteness, "WORD")

##Cognates
DutchWordList_w_Cognate <-left_join(DutchMaterialValConc, DutchEnglishCognates, "WORD")
#DutchCognateList <- DutchWordList_w_Cognate %>%
#  filter(Cognate == "1")
#14 out of 1286 words are cognates to remove
```

Finally I created DutchWordList tibble by removing cognates.

```{r}
DutchWordList <- DutchWordList_w_Cognate %>%
  replace(is.na(.),"0") %>%
  filter(Cognate == "0")
```

## Categorise target words and remove unknown words

At 2.3, I transformed two Valence ratings (English & Dutch) to the
normalised 0-1 scale (V_Mean_Percentage) so that two different likert
scales (7-point & 9-point) can be compared.

I followed @toivo2019 regarding how to categorise words into three
varence groups(Positive/Negative/Neutral); that is, based on the
normalised scale, words with a valence rating under 0.33 were
categorised as Negative, words with a valence rating over 0.66 were
categorised as Positive, and the rest were categorised as Neutral.

Also, words with \<75% KnownRatio are removed from the wordlists.
Although there was no English words with lower than 85% known ratio,
some Dutch words were applicable to this criteria thus removed from the
final dataset.

**English**

```{r}
EnglishWordList <- EnglishWordList %>% 
  mutate(V_Category = case_when(V_Mean_Percent > 0.66 ~ "Positive",
                                V_Mean_Percent < 0.33 ~ "Negative",
                                TRUE ~ "Neutral")) %>% 
  select(-CONTENT_WORD, -Cognate)
```

**Dutch**

```{r}
DutchWordList <- DutchWordList %>% 
  mutate(V_Category = case_when(V_Mean_Percent > 0.66 ~ "Positive",
                                V_Mean_Percent < 0.33 ~ "Negative",
                                TRUE ~ "Neutral")) %>%
  select(-CONTENT_WORD, -UnknownRatio, -Cognate)

DutchWordList <- DutchWordList %>%
  filter(!(C_Percent_known < 0.75))
```

## Create summary tables for WordLists

I excluded WORD_ID and then select unique rows to summarise the
characteristics of unique words in the target word lists.

**English**

```{r}
EnglishWordList_noDup <- EnglishWordList %>%
  select(-WORD_ID) %>%
  unique()

Sum_EnglishWordList <- EnglishWordList_noDup %>%
  group_by(V_Category) %>%
  summarise(N = n(),
            Mean_Valence_Percent = mean(V_Mean_Percent, na.rm = TRUE),
            SD_Valence_Percent = sd(V_Mean_Percent, na.rm = TRUE),
            Mean_WordLength = mean(WORD_LENGTH, na.rm = TRUE),
            SD_WordLength = sd(WORD_LENGTH, na.rm = TRUE),
            Mean_Conc = mean(Conc_Mean, na.rm = TRUE),
            SD_Conc = sd(Conc_Mean, na.rm = TRUE),
            Mean_KnownRatio = mean(C_Percent_known, na.rm = TRUE), #as there is no V_Percent_known data, using C_Percent_known
            SD_KnownRatio = sd(C_Percent_known, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(Language = "English")
```

**Dutch**

```{r}
DutchWordList_noDup <- DutchWordList %>%
  select(-WORD_ID) %>%
  unique()

Sum_DutchWordList <- DutchWordList_noDup %>%
  group_by(V_Category) %>%
  summarise(N = n(),
            Mean_Valence_Percent = mean(V_Mean_Percent, na.rm = TRUE),
            SD_Valence_Percent = sd(V_Mean_Percent, na.rm = TRUE),
            Mean_WordLength = mean(WORD_LENGTH, na.rm = TRUE),
            SD_WordLength = sd(WORD_LENGTH, na.rm = TRUE),
            Mean_Conc = mean(Conc_Mean, na.rm = TRUE),
            SD_Conc = sd(Conc_Mean, na.rm = TRUE),
            Mean_KnownRatio = mean(C_Percent_known, na.rm = TRUE), #C_Percent_known to match w/ English though V_Percent_known is available
            SD_KnownRatio = sd(C_Percent_known, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(Language = "Dutch")
```

**Summary**\
I combined two summary tables. Note that this table describes the
characteristics of the words in the target word list, which is created
with ReadingMaterial = the words in the novel. The target word list will
be compared with ReadingData, which contains the eye-tracking data
generated in the experiment.

```{r}
Sum_WordList <- bind_rows(Sum_DutchWordList,Sum_EnglishWordList)

df_Sum_WordList <- as.data.frame(Sum_WordList)
wordsummary <- data.frame(df_Sum_WordList$Language,
                          df_Sum_WordList$V_Category,
                          df_Sum_WordList$N,
                          round(df_Sum_WordList$Mean_Valence_Percent,3),
                          round(df_Sum_WordList$SD_Valence_Percent,3),
                          round(df_Sum_WordList$Mean_WordLength,2),
                          round(df_Sum_WordList$SD_WordLength,2),
                          round(df_Sum_WordList$Mean_Conc,2),
                          round(df_Sum_WordList$SD_Conc,2),
                          round(df_Sum_WordList$Mean_KnownRatio,3),
                          round(df_Sum_WordList$SD_KnownRatio,3))
names(wordsummary) <- (c("Language", "Valence Category", "N", "Valence rating (Mean)", "Valence rating (SD)", "Word Length (Mean)", "Word Length (SD)", "Concreteness rating (Mean)", "Concreteness rating (SD)", "Word known ratio (Mean)", "Word known ratio (SD)"))

kable(wordsummary) %>% kable_styling()
```

## Visualisation of target word lists

For the reference, I created histograms for valence ratings of the
target words. From the histogram, you can see that 1) English valence
rating seems negatively skewed, and 2) Dutch valence rating seems
normally distributed.

**English**

```{r warning=FALSE}
ggplot(EnglishWordList_noDup, aes(V_Mean_Percent)) + 
  geom_histogram(binwidth = .01,
                 colour = "black",
                 fill = "grey",
                 aes(y = ..density..)) + 
  scale_x_continuous(name = "English Mean Valence (0-1)") +
  stat_function(fun = dnorm, # this adds a normal density function curve
                colour = "red", # this makes it red
                args = list(mean = mean(EnglishWordList_noDup$V_Mean_Percent, na.rm = TRUE),
                           sd = sd(EnglishWordList_noDup$V_Mean_Percent, na.rm = TRUE)))
```

**Dutch**

```{r warning=FALSE}
ggplot(DutchWordList_noDup, aes(V_Mean_Percent)) + 
  geom_histogram(binwidth = .01,
                 colour = "black",
                 fill = "grey",
                 aes(y = ..density..)) + 
  scale_x_continuous(name = "Dutch Mean Valence (0-1)") +
  stat_function(fun = dnorm, # this adds a normal density function curve
                colour = "red", # this makes it red
                args = list(mean = mean(DutchWordList_noDup$V_Mean_Percent, na.rm = TRUE),
                           sd = sd(DutchWordList_noDup$V_Mean_Percent, na.rm = TRUE)))
```

## Demographic information

First of all, I loaded the dataset and selected only necessary
information. One participant(pp18) was removed from the dataset because
they only read first half of the book in English [@cop2016].

```{r}
#Load the dataset
Demographic <- read_excel("SubjectInformation.xlsx")

#Select necessary information.
Demographic <- Demographic %>%
  select(PP_NR, GROUP, AGE, SEX, AOA_ENG) %>%
  filter(GROUP == "bilingual") %>%
  mutate(PP_NR_N = recode(PP_NR, #Change PP_NR label to match with ReadingData
                          "1" = "pp01",
                          "2" = "pp02",
                          "3" = "pp03",
                          "4" = "pp04",
                          "5" = "pp05",
                          "6" = "pp06",
                          "7" = "pp07",
                          "8" = "pp08",
                          "9" = "pp09",
                          "10" = "pp10",
                          "11" = "pp11",
                          "12" = "pp12",
                          "13" = "pp13",
                          "14" = "pp14",
                          "15" = "pp15",
                          "16" = "pp16",
                          "17" = "pp17",
                          "18" = "pp18",
                          "19" = "pp19")) %>%
  select(PP_NR_N, GROUP, AGE, SEX, AOA_ENG) %>%
  rename(PP_NR = PP_NR_N) %>%
  filter(!(PP_NR == "pp18")) #remove pp18

```

Demographic information is summarised in the Demographic_table tibble.

```{r}
Demographic_table <- Demographic %>%
  summarise(N = n(),
            MAge = mean(AGE, na.rm = TRUE),
            SDAge = sd(AGE, na.rm = TRUE),
            MAoA = mean(AOA_ENG, na.rm = TRUE),
            SDAoA = sd(AOA_ENG, na.rm = TRUE))

kable(Demographic_table) %>% kable_styling()
```

## Data wrangling on ReadingData

Here I uploaded the ReadingData from GECO project [@cop2016], retrieved
from <https://expsy.ugent.be/downloads/geco/>. For the analyses, I
selected PP_NR, PART, WORD, WORD_FIXATION_COUNT,
WORD_FIRST_FIXATION_DURATION. Single Fixation Duration (SFD) is our
dependent variables which are the Words that has WORD_FIXATION_COUNT =
1.

**English**

```{r}
EnglishReadingData_raw <- read_excel("L2ReadingData.xlsx")

EnglishReadingData <- EnglishReadingData_raw %>% 
  select(PP_NR, PART, WORD_ID, WORD, WORD_FIXATION_COUNT, WORD_FIRST_FIXATION_DURATION) %>%
  filter(WORD_FIXATION_COUNT == "1",
         !(PP_NR == "pp18")) #pp18 is removed as this participant only completed half of the experiment
```

The reading data contains punctuation, which needs to be removed so that
we can combine the reading data with target wordlists.

```{r}
EnglishReadingData_Final <- EnglishReadingData %>%
  mutate(WORD2 = lapply(WORD, function(x) {str_replace_all(x,"[,.'?!:;-]","")})) #Remove ,.'?! from WORD and keep the results in WORD2
EnglishReadingData_Final$WORD3 <- gsub(x=EnglishReadingData_Final$WORD2, pattern ="\"", "") #Remove "" from WORD2 and keep the results in WORD3

EnglishReadingData_Final <- EnglishReadingData_Final %>%
  select(PP_NR, PART, WORD_ID, WORD3, WORD_FIXATION_COUNT, WORD_FIRST_FIXATION_DURATION) %>%
  rename(WORD = WORD3) %>%
  mutate(WORD_FIRST_FIXATION_DURATION = as.numeric(WORD_FIRST_FIXATION_DURATION))
```

**Dutch**\
Same cleaning process as English is required for Dutch reading data.

```{r}
DutchReadingData_raw <- read_excel("L1ReadingData.xlsx")

DutchReadingData <- DutchReadingData_raw %>%
  select(PP_NR, PART, WORD_ID, WORD, WORD_FIXATION_COUNT, WORD_FIRST_FIXATION_DURATION) %>%
  filter(WORD_FIXATION_COUNT == "1")
        
DutchReadingData_Final <- DutchReadingData %>%
  mutate(WORD2 = lapply(WORD, function(x) {str_replace_all(x,"[,.'?!:;-]","")}))
DutchReadingData_Final$WORD3 <- gsub(x=DutchReadingData_Final$WORD2, pattern ="\"", "")
DutchReadingData_Final <- DutchReadingData_Final %>%
  select(PP_NR, PART, WORD_ID, WORD3, WORD_FIXATION_COUNT, WORD_FIRST_FIXATION_DURATION) %>%
  rename(WORD = WORD3) %>%
  mutate(WORD_FIRST_FIXATION_DURATION = as.numeric(WORD_FIRST_FIXATION_DURATION))
```

## Join ReadingData and Target Word Lists

We used WORD_ID to join the two tibbles.

**English**

There are 55737 words after the ReadingData_Final is compared against
the target word list.

```{r}
EnglishReadingData_w_WordList <- inner_join(EnglishReadingData_Final, EnglishWordList, "WORD_ID") %>%
  select(-WORD.y) %>%
  rename(WORD = WORD.x)
```

**Dutch**

There are 47333 words after the ReadingData_Final is compared against
the target word list.

```{r}
DutchReadingData_w_WordList <- inner_join(DutchReadingData_Final,DutchWordList, "WORD_ID") %>%
  select(-WORD.y, -Translation, -V_Percent_known) %>%
  rename(WORD = WORD.x)
```

## Detect outliers

Single Fixation Duration (SFD) that differed more than 2.5 standard
deviations from the subject means were considered outliers and excluded
from the dataset.

**English**

```{r}
SubjectMeanSFD_EN <- EnglishReadingData_w_WordList %>%
  group_by(PP_NR) %>%
  summarise(SFDSubjectMean = mean(WORD_FIRST_FIXATION_DURATION, na.rm = TRUE),
            SFDSubjectSD = sd(WORD_FIRST_FIXATION_DURATION, na.rm = TRUE)) %>%
  ungroup()

EnglishReadingData_w_WordList <- inner_join(EnglishReadingData_w_WordList, SubjectMeanSFD_EN, "PP_NR")
EnglishReadingData_w_WordList_Outlier <- EnglishReadingData_w_WordList %>%
  mutate(Outlier = case_when(WORD_FIRST_FIXATION_DURATION > SFDSubjectMean + (SFDSubjectSD * 2.5) ~ "1",
                             WORD_FIRST_FIXATION_DURATION < SFDSubjectMean - (SFDSubjectSD * 2.5) ~ "1",
                             TRUE ~ "0")) # Outliers if 1

EnglishReadingData_w_WordList <- EnglishReadingData_w_WordList_Outlier %>%
  filter(Outlier == "0")

```

According to the summary created below, 1,189 of 55,737 items are
identified as outliers in EnglishReadingData.

```{r}
Sum_Outlier_EN <- EnglishReadingData_w_WordList_Outlier %>%
  group_by(Outlier) %>%
  summarise(n = n()) %>%
  ungroup()

Sum_Outlier_EN
```

**Dutch**

```{r}
SubjectMeanSFD_NL <- DutchReadingData_w_WordList %>%
  group_by(PP_NR) %>%
  summarise(SFDSubjectMean = mean(WORD_FIRST_FIXATION_DURATION, na.rm = TRUE),
            SFDSubjectSD = sd(WORD_FIRST_FIXATION_DURATION, na.rm = TRUE)) %>%
  ungroup()

DutchReadingData_w_WordList <- inner_join(DutchReadingData_w_WordList, SubjectMeanSFD_NL, "PP_NR")
DutchReadingData_w_WordList_Outlier <- DutchReadingData_w_WordList %>%
  mutate(Outlier = case_when(WORD_FIRST_FIXATION_DURATION > SFDSubjectMean + (SFDSubjectSD * 2.5) ~ "1",
                             WORD_FIRST_FIXATION_DURATION < SFDSubjectMean - (SFDSubjectSD * 2.5) ~ "1",
                             TRUE ~ "0")) # Outliers if 1


DutchReadingData_w_WordList <- DutchReadingData_w_WordList_Outlier %>%
  filter(Outlier == "0")
```

According to the summary created below, 1,000 of 47,333 items are
identified as outliers in DutchReadingData.

```{r}
Sum_Outlier_NL <- DutchReadingData_w_WordList_Outlier %>%
  group_by(Outlier) %>%
  summarise(n = n()) %>%
  ungroup()

Sum_Outlier_NL
```

## Account for the repeated words in the datasets

Repeated words refer to the target words that are repeated multiple
times in the ReadingData (e.g., "that" in English). Here, I added a new
column that flags if the target words are repeated in the ReadingData
dataset.

**English**\
According to the below summary, there are 18005 target words in reading
dataset, in which 8037 words are repeated. That means, 44.64% of words
are repeated with a range of 2-129 times.

```{r message = FALSE}
Sum_EnglishReadingData_w_WordList <- EnglishReadingData_w_WordList %>%
  group_by(PP_NR, WORD) %>%
  summarise(N = n()) %>%
  ungroup() %>%
  mutate(Repeated = case_when(N > 1 ~ "1",
                              TRUE ~"0"))

count(Sum_EnglishReadingData_w_WordList, Repeated == "0")
```

I created visualisation to find characteristics of these repeated words.
Here you can see that most of repeated words are only repeated twice or
three times.

```{r message=FALSE}
Sum2_EnglishReadingData_w_WordList <- Sum_EnglishReadingData_w_WordList %>%
  filter(Repeated == "1")

ggplot(Sum2_EnglishReadingData_w_WordList, aes(N)) +
  geom_bar()
```

**Dutch**\
According to the below summary, there are 11487 target words in reading
dataset, in which 5933 words are repeated. That means, 51.65% of words
are repeated with a range of 2-253 times.

```{r message=FALSE}
Sum_DutchReadingData_w_WordList <- DutchReadingData_w_WordList %>%
  group_by(PP_NR, WORD) %>%
  summarise(N = n()) %>%
  ungroup() %>%
  mutate(Repeated = case_when(N > 1 ~ "1",
                              TRUE ~"0"))

count(Sum_DutchReadingData_w_WordList, Repeated == "0")
```

Visualisations are created for Dutch data as well. Same as English data,
you can see that most of repeated words are only repeated twice or three
times.

```{r}
Sum2_DutchReadingData_w_WordList <- Sum_DutchReadingData_w_WordList %>%
  filter(Repeated == "1")

#Most of repeated words only repeated twice/three times
ggplot(Sum2_DutchReadingData_w_WordList, aes(N)) +
  geom_bar()
```

## Clean up repeating words in ReadingData

Based on the analysis at 2.14, we concluded that the word proportion of
repeated words is not significant (= less than 80%). Thus, we keep only
the first instance of each of the repeating words per participant for
our analysis. Here I used slice(1) to select the first row. slice_head()
would also work. If want random selection, slice_sample() can be used
instead of slice(\#) or slice_head().

**English**

```{r}
EnglishReadingData_w_WordList_NoRep <- EnglishReadingData_w_WordList %>%
  group_by(PP_NR, WORD) %>%
  slice(1) %>% 
  ungroup()
```

**Dutch**

```{r}
DutchReadingData_w_WordList_NoRep <- DutchReadingData_w_WordList %>%
  group_by(PP_NR, WORD) %>%
  slice(1) %>%
  ungroup()
```

## Summary of words for analysis

ReadingData_raw contains 549,290 words for Dutch and 534,154 words for
English. After selecting SFD and compared against our target word list,
the number of words is 47,333 (Dutch) and 55,737 (English), which is
9.51% of the raw data. Then we selected only one appearance per word per
person, which made the number of words for our analysis 11,487 (Dutch)
and 18,005 (English), 2.72% of the raw data.

I created a summary table of the words in ReadingData dataset that are
analysed in the current study.

```{r message=FALSE}
ReadingData_w_WordList_NoRep <- bind_rows(EnglishReadingData_w_WordList_NoRep, DutchReadingData_w_WordList_NoRep)

Sum_ReadingData_ENandNL <- ReadingData_w_WordList_NoRep %>%
  select(Language, V_Category, V_Mean_Percent, WORD_LENGTH, Conc_Mean, C_Percent_known) %>%
  group_by(Language, V_Category) %>%
  summarise(N = n(),
            Mean_Valence_Percent = mean(V_Mean_Percent, na.rm = TRUE),
            SD_Valence_Percent = sd(V_Mean_Percent, na.rm = TRUE),
            Mean_WordLength = mean(WORD_LENGTH, na.rm = TRUE),
            SD_WordLength = sd(WORD_LENGTH, na.rm = TRUE),
            Mean_Conc = mean(Conc_Mean, na.rm = TRUE),
            SD_Conc = sd(Conc_Mean, na.rm = TRUE),
            Mean_KnownRatio = mean(C_Percent_known, na.rm = TRUE),
            SD_KnownRatio = sd(C_Percent_known, na.rm = TRUE)) %>%
  ungroup()

df_Sum_ReadingData <- as.data.frame(Sum_ReadingData_ENandNL)
ReadingDataSummary <- data.frame(df_Sum_ReadingData$Language,
                                 df_Sum_ReadingData$V_Category,
                                 df_Sum_ReadingData$N,
                                 round(df_Sum_ReadingData$Mean_Valence_Percent,2),
                                 round(df_Sum_ReadingData$SD_Valence_Percent,2),
                                 round(df_Sum_ReadingData$Mean_WordLength,2),
                                 round(df_Sum_ReadingData$SD_WordLength,2),
                                 round(df_Sum_ReadingData$Mean_Conc,2),
                                 round(df_Sum_ReadingData$SD_Conc,2),
                          round(df_Sum_ReadingData$Mean_KnownRatio,3),
                          round(df_Sum_ReadingData$SD_KnownRatio,3))
names(ReadingDataSummary) <- (c("Language", "Valence Category", "N", "Valence rating (Mean)", "Valence rating (SD)", "Word Length (Mean)", "Word Length (SD)", "Concreteness rating (Mean)", "Concreteness rating (SD)", "Word known ratio (Mean)", "Word known ratio (SD)"))

kable(ReadingDataSummary) %>% kable_styling()
```

Here I also summarised the number of items per participant per language.

```{r message=FALSE}
Sum_ReadingData_ENandNL_itemsperparticipants <- ReadingData_w_WordList_NoRep %>%
  group_by(PP_NR, Language) %>%
  summarise(N = n()) %>%
  ungroup()

kable(Sum_ReadingData_ENandNL_itemsperparticipants) %>% kable_styling()
```

## Mean centering

All continuous variable will be centred to reduce collinearity between
main effects and interactions: WORD_FIRST_FIXATION_DURATION,
WORD_LENGTH, Conc_Mean. When you have continuous variables in a
regression, it is often sensible to transform them by mean centering.
You mean center a predictor X simply by subtracting the mean (X_centered
= X - mean(X)). This has two useful consequences:
<https://psyteachr.github.io/msc-conv/multiple-regression.html>

```{r}
ReadingData_ENandNL <- ReadingData_w_WordList_NoRep %>%
  select(-WORD_FIXATION_COUNT, -V_SD, -Conc_SD,-C_Percent_known, -SFDSubjectMean, - SFDSubjectSD, -Outlier) %>% #Cleaning up the tibble by removing columns that are no longer required for analysis
  mutate(WORD_FIRST_FIXATION_DURATION_centered = WORD_FIRST_FIXATION_DURATION - mean(WORD_FIRST_FIXATION_DURATION),
         WORD_LENGTH_centered = WORD_LENGTH - mean(WORD_LENGTH),
         Conc_Mean_centered = Conc_Mean - mean(Conc_Mean))
```

## Summary of SFD

Summary of Single Fixation Duration is also created as below.

```{r warning=FALSE, message=FALSE}
Sum_SFD <- ReadingData_ENandNL %>%
  group_by(V_Category, Language) %>%
  summarise(Mean = mean(WORD_FIRST_FIXATION_DURATION),
            SD = sd(WORD_FIRST_FIXATION_DURATION)) %>%
  ungroup()

df_Sum_SFD <- as.data.frame(Sum_SFD)
SFDsummary <- data.frame(df_Sum_SFD$Language,
                         df_Sum_SFD$V_Category,
                         round(df_Sum_SFD$Mean,2),
                         round(df_Sum_SFD$SD,2))
names(SFDsummary) <- (c("Language", "Valence Category", "SFD (Mean)", "SFD (SD)"))

Sum_SFDwoLang <- ReadingData_ENandNL %>%
  group_by(V_Category) %>%
  summarise(Mean = mean(WORD_FIRST_FIXATION_DURATION),
            SD = sd(WORD_FIRST_FIXATION_DURATION)) %>%
  ungroup()

df_Sum_SFDwoLang <- as.data.frame(Sum_SFDwoLang)
SFDsummary_woLang <- data.frame(df_Sum_SFDwoLang$V_Category,
                         round(df_Sum_SFDwoLang$Mean,2),
                         round(df_Sum_SFDwoLang$SD,2))
names(SFDsummary_woLang) <- (c("Valence Category", "SFD (Mean)", "SFD (SD)")) 

kable(SFDsummary) %>% kable_styling()
kable(SFDsummary_woLang) %>% kable_styling()
```


<!--chapter:end:01-setup-dataprep.Rmd-->

# Statistical Analysis

## Deviation coding and dummy coding
Deviation coding are conducted for Language(independent variable) and valence rating(independent variable). We also conducted dummy coding for valence categories in case that interactions are significant and needed to be decomposed to detect single effect.
```{r}
#Deviation coding
ReadingData_ENandNL <- ReadingData_ENandNL %>%
  mutate(Language_dev = if_else(Language == "Dutch", .5, -.5),
         V_Category_NeuPos_dev = if_else(V_Category == "Positive", 2/3, -1/3),
         V_Category_NeuNeg_dev =  if_else(V_Category == "Negative", 2/3, -1/3))

#Dummy coding
ReadingData_ENandNL <- ReadingData_ENandNL %>%
  mutate(V_Category_NeuPos_dum = if_else(V_Category == "Positive", 1, 0),
         V_Category_NeuNeg_dum = if_else(V_Category == "Negative", 1, 0))

```


```{r echo=FALSE}
save(ReadingData_ENandNL,file='C:/Users/ibana/OneDrive - University of Glasgow/@Year 3/For Publication/Data and Code/final_reading_data.RData')
```


## Find a best-fit model
SFD(dependent variable) is skewed, thus we decided to use glmer() to perform generalised linear mixed-effect model (GLMM).

Here I left the coding for crafting models from simple to complex.
```{r}
#random effects (interception)

#Step A simple model with Gamma model. 
#I did not use the mean-centered variables as it gave me error message.
#mod <- glmer(WORD_FIRST_FIXATION_DURATION ~
#                #Main effects
#                V_Category_NeuPos_dev + 
#                V_Category_NeuNeg_dev + 
#                Language_dev +
#                #Control variables
#                WORD_LENGTH +
#                Conc_Mean +
#                #Interactions
#                V_Category_NeuPos_dev:Language_dev +  
#                V_Category_NeuNeg_dev:Language_dev + 
#                #Random effects
#                (1|WORD)+ (1|PP_NR), data = ReadingData_ENandNL, family = Gamma(link="identity"))

#Step B: start adding slopes
#mod3 <- glmer(WORD_FIRST_FIXATION_DURATION~
#                #Main effects
#                V_Category_NeuPos_dev + 
#                V_Category_NeuNeg_dev + 
#                Language_dev +
#                #Control variables
#                WORD_LENGTH +
#                Conc_Mean +
#                #Interactions
#                V_Category_NeuPos_dev:Language_dev +  
#                V_Category_NeuNeg_dev:Language_dev + 
#                #Random effects
#                (1|WORD)+ (1 + Language_dev + V_Category_NeuPos_dev + V_Category_NeuNeg_dev | PP_NR), data = ReadingData_ENandNL, family=Gamma(link="identity"))

#Added random slope to WORD as well as PP_NR
#mod4 <- glmer(WORD_FIRST_FIXATION_DURATION~
#                #Main effects
#                V_Category_NeuPos_dev + 
#                V_Category_NeuNeg_dev + 
#                Language_dev +
#                #Control variables
#                WORD_LENGTH +
#                Conc_Mean +
#               #Interactions
#                V_Category_NeuPos_dev:Language_dev +  
#                V_Category_NeuNeg_dev:Language_dev + 
#                #Random effects
#                (1 + Language_dev + V_Category_NeuPos_dev + V_Category_NeuNeg_dev |WORD)+ (1 + Language_dev + V_Category_NeuPos_dev + V_Category_NeuNeg_dev | PP_NR), 
#                data = ReadingData_ENandNL, family=Gamma(link="identity"))

#Step C: Maximal model
#mod5 <- glmer(WORD_FIRST_FIXATION_DURATION ~
#                #Main effects
#                V_Category_NeuPos_dev + 
#                V_Category_NeuNeg_dev + 
#                Language_dev +
#                #Control variables
#                WORD_LENGTH +
#                Conc_Mean +
#                #Interactions
#                V_Category_NeuPos_dev:Language_dev +  
#                V_Category_NeuNeg_dev:Language_dev + 
#                #Random effects
#                (1|WORD)+ (1+Language_dev + V_Category_NeuPos_dev +V_Category_NeuNeg_dev + Conc_Mean + WORD_LENGTH | PP_NR), 
#                data = ReadingData_ENandNL, family=Gamma(link="identity"))

```

After running multiple models, I decided to go for a maxibal model which includes random slopes and intercepts for both participants and words (subjects and items). This serves as our baseline model = mod.
```{r eval=FALSE}
mod <- glmer(WORD_FIRST_FIXATION_DURATION ~
             #Main effects
             V_Category_NeuPos_dev + 
             V_Category_NeuNeg_dev + 
             Language_dev +
             #Control variables
             Conc_Mean +
             WORD_LENGTH +
             #Interactions
             V_Category_NeuPos_dev:Language_dev +  
             V_Category_NeuNeg_dev:Language_dev + 
             #Random effects
             (1 + Language_dev + V_Category_NeuPos_dev + V_Category_NeuNeg_dev + Conc_Mean + WORD_LENGTH | WORD)+ (1 + Language_dev + V_Category_NeuPos_dev + V_Category_NeuNeg_dev + Conc_Mean + WORD_LENGTH | PP_NR), 
             data = ReadingData_ENandNL, family=Gamma(link="identity"), control = glmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "L-BFGS-B", maxit = 10000, starttests = FALSE, kkt = FALSE)))

save(mod,file='C:/Users/ibana/OneDrive - University of Glasgow/@Year 3/For Publication/Data and Code/mod_results.RData')
```

```{r echo = FALSE}
load("mod_results.RData")
```


Here I also created a baseline model with original categorical variables; that is, non-deviation coded variables are used for mod2.
```{r eval = FALSE}
mod2 <- glmer(WORD_FIRST_FIXATION_DURATION ~
             #Main effects
             V_Category + 
             Language +
             #Control variables
             Conc_Mean +
             WORD_LENGTH +
             #Interactions
             V_Category:Language + 
             #Random effects
             (1 + Language + V_Category + Conc_Mean + WORD_LENGTH | WORD)+ (1 + Language + V_Category + Conc_Mean + WORD_LENGTH | PP_NR), 
             data = ReadingData_ENandNL, family=Gamma(link="identity"), control = glmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "L-BFGS-B", maxit = 10000, starttests = FALSE, kkt = FALSE)))

save(mod2,file='C:/Users/ibana/OneDrive - University of Glasgow/@Year 3/For Publication/Data and Code/mod2_results.RData')
```

```{r echo = FALSE}
load("mod2_results.RData")
```


I created the summary of the model for reporting.
```{r}
modelsummary<- broom.mixed::tidy(mod, effects = c("ran_pars", "fixed"),scales = NULL, ran_prefix = NULL, conf.int = TRUE, conf.level = 0.95, conf.method = "Wald") %>% 
  filter(effect =="fixed")

df_modelsummary <- as.data.frame(modelsummary)
modelsummary <- data.frame(df_modelsummary$term, 
                      round(df_modelsummary$estimate,2), 
                      round(df_modelsummary$std.error,2), 
                      round(df_modelsummary$statistic,2), 
                      round(df_modelsummary$p.value,2), 
                      round(df_modelsummary$conf.low,2), 
                      round(df_modelsummary$conf.high,2))
names(modelsummary) <- (c("Term", "Estimate", "Standard Error", "t-value", "p-value", "95% CI (Lower)", "95% CI (Higher)"))
modelsummary$`p-value` <- ifelse(modelsummary$`p-value` <0.001, "<0.001", round(modelsummary$`p-value`, 3))

kable(modelsummary) %>% kable_styling()
```

## Run model comparison for the main effect and interactions
First of all, I created reduced models (mod3, mod4, mod5) by removing main effect of valence, language, and interaction from the baseline model, respectively.
```{r eval=FALSE}
#Removing main effect of valence from mod
mod3 <- update(mod, . ~ . - V_Category_NeuPos_dev - V_Category_NeuNeg_dev)

#Removing main effect of language from mod
mod4 <- update(mod, . ~ . - Language_dev)

#Removing interaction from mod
mod5 <- update(mod, . ~ . - V_Category_NeuPos_dev:Language_dev - V_Category_NeuNeg_dev:Language_dev)


save(mod3,file='C:/Users/ibana/OneDrive - University of Glasgow/@Year 3/For Publication/Data and Code/mod3_results.RData')
save(mod4,file='C:/Users/ibana/OneDrive - University of Glasgow/@Year 3/For Publication/Data and Code/mod4_results.RData')
save(mod5,file='C:/Users/ibana/OneDrive - University of Glasgow/@Year 3/For Publication/Data and Code/mod5_results.RData')
```

```{r echo = FALSE}
load("mod3_results.RData")
load("mod4_results.RData")
load("mod5_results.RData")
```


Then I ran model comparison. Model comparison was conducted with ANOVA.
```{r}
mod_mod3 <- anova(mod, mod3) #baseline model vs reduced wo valence effect
mod_mod4 <- anova(mod, mod4) #baseline model vs reduced wo language
mod_mod5 <- anova(mod, mod5) #baseline model vs reduced wo val x lang interaction
```
The likelihood ratio test confirmed that the effect of valence was also significant ($\chi^{2}$(2) = 6.81, *p* = .03).
```{r}
kable(mod_mod3) %>% kable_styling
```

The main effect of language is also significant ($\chi^{2}$(1) = 25.44, *p* < .001).
```{r}
kable(mod_mod4) %>% kable_styling
```

Valence x language interaction was not statistically significant ($\chi^{2}$(2) = 3.40, *p* = .18).
```{r}
kable(mod_mod5) %>% kable_styling
```


## Decompose the significant effects of valence
The significant main effect of valence is decomposed with emmeans() function. I used revpairwise to reverse the direction of comparison for easier reporting.
```{r, message=FALSE}
Posthoc_V_NeuPos <- emmeans(mod, list(revpairwise ~ V_Category_NeuPos_dev), adjust = "tukey")
Posthoc_V_NeuNeg <- emmeans(mod, list(revpairwise ~ V_Category_NeuNeg_dev), adjust = "tukey")
```
Here, 0.66 refers to Positive, -0.33 refers to Neutral.
```{r}
Posthoc_V_NeuPos

confint(Posthoc_V_NeuPos)
```
Thus you can interpret the table as:

Value           |estimate|SE  |df |z.ratio|p.value|asymp.LCL|asymp.UCL
----------------|--------|----|---|-------|-------|---------|---------
Positive-Neutral|   -5.44|1.41|Inf| -3.852| 0.0001|    -8.21|    -2.67

Here, 0.66 refers to Negative, -0.33 refers to Neutral.
```{r}
Posthoc_V_NeuNeg

confint(Posthoc_V_NeuNeg)
```
Thus you can interpret the table as:

Value           |estimate|SE  |df |z.ratio|p.value|asymp.LCL|asymp.UCL
----------------|--------|----|---|-------|-------|---------|---------
Negative-Neutral|  -0.263|1.71|Inf| -0.154| 0.8780|    -3.62|      3.1

## Expolatory analysis: compare positive vs negative
```{r  eval = FALSE}
ReadingData_ENandNL_PosNeg <- ReadingData_ENandNL %>%
  select(-V_Category_NeuPos_dev, - V_Category_NeuNeg_dev) %>%
  mutate(V_Category_PosNeu_dev = if_else(V_Category == "Neutral", 2/3, -1/3),
         V_Category_PosNeg_dev = if_else(V_Category == "Negative", 2/3, -1/3))

mod6 <- glmer(WORD_FIRST_FIXATION_DURATION ~
              #Main effects
              V_Category_PosNeu_dev + 
              V_Category_PosNeg_dev + 
              Language_dev +
              #Control variables
              Conc_Mean +
              WORD_LENGTH +
              #Interactions
              V_Category_PosNeu_dev:Language_dev + 
              V_Category_PosNeg_dev:Language_dev + 
              #Random effects
              (1 + Language_dev + V_Category_PosNeu_dev + V_Category_PosNeg_dev + Conc_Mean + WORD_LENGTH | WORD)+ (1 + Language_dev + V_Category_PosNeu_dev + V_Category_PosNeg_dev + Conc_Mean + WORD_LENGTH | PP_NR), 
              data = ReadingData_ENandNL_PosNeg, family=Gamma(link="identity"), control = glmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "L-BFGS-B", maxit = 10000, starttests = FALSE, kkt = FALSE)))

save(mod6,file='C:/Users/ibana/OneDrive - University of Glasgow/@Year 3/For Publication/Data and Code/mod6_results.RData')
```

```{r eval=FALSE, echo=FALSE}
#Reduced model for main effects
mod10 <- update(mod6, . ~ . - V_Category_PosNeu_dev - V_Category_PosNeg_dev)
save(mod10,file='C:/Users/ibana/OneDrive - University of Glasgow/@Year 3/For Publication/Data and Code/mod10_results.RData')

#Reduced emodel for interaction
mod11 <- update(mod6, ~ . - V_Category_PosNeu_dev:Language_dev - V_Category_PosNeg_dev:Language_dev)
save(mod11,file='C:/Users/ibana/OneDrive - University of Glasgow/@Year 3/For Publication/Data and Code/mod11_results.RData')
```

```{r echo=FALSE}
load("mod6_results.RData")
```

The effect of valence is decomposed with emmeans().
```{r message=FALSE}
Posthoc_V_PosNeg <- emmeans(mod6, list(pairwise ~ V_Category_PosNeg_dev), adjust = "tukey")

Posthoc_V_PosNeg

confint(Posthoc_V_PosNeg)
```
Here -0.33 refers to Positive and 0.66 refers to Negative.
Thus you can interpret the table as:

Value            |estimate|SE  |df |z.ratio|p.value|asymp.LCL|asymp.UCL
-----------------|--------|----|---|-------|-------|---------|---------
Positive-Negative|   -5.29|2.01|Inf| -2.631| 0.0085|    -9.23|    -1.35

## Decompose the non-significant effect of interaction
The model comparison did not provide significant results for interaction of Valence x Language, but mod showed V_Category_NeuPos_dev:Language_dev was significant. Decomposing the results here to look into it deeply.
```{r}
Posthoc_Int_NeuPosLang <- emmeans(mod, list(revpairwise ~ V_Category_NeuPos_dev:Language_dev), adjust = "tukey" )
Posthoc_Int_NeuNegLang <- emmeans(mod, list(revpairwise ~ V_Category_NeuNeg_dev:Language_dev), adjust = "tukey" )
Posthoc_Int_PosNegLang <- emmeans(mod6, list(pairwise ~ V_Category_PosNeg_dev:Language_dev), adjust = "tukey" )
```

The Language_dev -0.5 refers to English, 0.5 refers to English. To decompose the non-significant interaction of valence x language, we only look at the pairwise difference with same languages, which are on the top and bottom rows.
```{r}
Posthoc_Int_NeuPosLang
confint(Posthoc_Int_NeuPosLang)
```

In the above table, 0.66 refers to Positive, 0.33 refers to Neutral. As we only focus on the top and bottom rows of the data, we extract these results:

Language|Interaction     |estimate|SE  |df |z.ratio|p.value|asymp.LCL|asymp.UCL
--------|----------------|--------|----|---|-------|-------|---------|---------
English |Positive-Neutral|   -8.52|1.78|Inf| -4.778| <.0001|   -13.11|    -3.94
Dutch   |Positive-Neutral|   -2.36|2.03|Inf| -1.159| 0.6526|    -7.58|     2.87

We will do the same for the other two tables.

```{r}
Posthoc_Int_NeuNegLang
confint(Posthoc_Int_NeuNegLang)
```

Language|Interaction     |estimate|SE  |df |z.ratio|p.value|asymp.LCL|asymp.UCL
--------|----------------|--------|----|---|-------|-------|---------|---------
English |Negative-Neutral|  -0.393|2.34|Inf| -0.168| 0.9983|    -6.40|     5.62
Dutch   |Negative-Neutral|  -0.133|2.33|Inf| -0.057| 0.9999|    -6.13|     5.86

```{r}
Posthoc_Int_PosNegLang
confint(Posthoc_Int_PosNegLang)
```

Language|Interaction      |estimate|SE  |df |z.ratio|p.value|asymp.LCL|asymp.UCL
--------|-----------------|--------|----|---|-------|-------|---------|---------
English |Positive-Negative|   -8.31|2.63|Inf| -3.156| 0.0087|    -15.1|    -1.55
Dutch   |Positive-Negative|   -2.27|2.74|Inf| -0.830| 0.8403|     -9.3|     4.76

<!--chapter:end:02-stats-analysis.Rmd-->

# Visualisation

```{r echo=FALSE}
load("mod_results.RData")
load("mod2_results.RData")
load("final_reading_data.RData")
```

## The final reading dataset
A violin-box plot is created for the final reading dataset for analysis. 
```{r warning=FALSE}
ggplot(ReadingData_ENandNL, aes(x = V_Category, y = WORD_FIRST_FIXATION_DURATION, fill = V_Category)) +
  geom_violin(alpha = .6) +
  geom_boxplot(width = .2, alpha = .6) +
  stat_summary(fun = "mean", geom = "point",
               position = position_dodge(.9)) +
  stat_summary(fun.data = "mean_se", geom = "errorbar", width = .1,
               position = position_dodge(.9))+
  scale_x_discrete(name = "Valence Category") +
  scale_y_continuous(name = "Single Fixation Duration (ms)") +
  scale_fill_viridis_d(option = "E") + 
  facet_wrap(~Language) +
  theme_bw() +
  guides(fill = FALSE)
```

## The baseline model (mod)
I created a Blobbogram for Generalised linear mixed-effect model.broom.mixed::tidy() works on LMM to create a model summary. I then added factor to split the data for colours.
```{r message= FALSE, warning= FALSE}
modelsummary_vis <- broom.mixed::tidy(mod, effects = c("ran_pars", "fixed"),scales = NULL, ran_prefix = NULL, conf.int = TRUE, conf.level = 0.95, conf.method = "Wald") %>% 
  filter(effect =="fixed") %>% filter(term!="(Intercept)")

#Add factor to split the data for colours
modelsummary_vis$Type <- as.factor(ifelse(str_detect(modelsummary_vis$term, ":"), "Interaction", "Main effect"))
```

Below ggplot() coding was run to generate a Blobbogram. Condition1 refers to Positive vs Neutral; Condition2 refers to Negative vs Neutral. The minimal theme is applied to make it black & white = colourblind friendly.
```{r message= FALSE, warning= FALSE}
ggplot(modelsummary_vis, aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high, shape = Type)) + 
  geom_pointrange() +
  ylab("Estimates with 95% CIs") + 
  geom_hline(aes(yintercept = 0), linetype = "dashed") +
  scale_x_discrete(limits = c("V_Category_NeuNeg_dev:Language_dev", "V_Category_NeuPos_dev:Language_dev", "WORD_LENGTH", "Conc_Mean",  "Language_dev", "V_Category_NeuNeg_dev", "V_Category_NeuPos_dev"),
                   labels = c("Condition2:Language", "Condition1:Language", "Word Length", "Concreteness", "Language", "Condition2", "Condition1")) +
  xlab("Fixed effect") +
  coord_flip() +
  theme_bw()
```

## emmip: Interaction-style plots for estimated marginal means
```{r message= FALSE, warning= FALSE}
plot_dat <- emmip(mod2, Language~V_Category, plotit = FALSE)

ggplot(plot_dat, aes(x = xvar, y = yvar, group = tvar, linetype = tvar, shape = tvar)) +
    geom_point(size = 2) +
    geom_line() +
    labs(x = "Valence Category", y = "Single Fixation Duration (ms)", linetype = "Language", shape = "Language") +
    theme_bw()
```

## Assumption Checking
1. Linearity
```{r message= FALSE, warning= FALSE}
plot(fitted(mod), residuals(mod))
```

2. Absence of collinearity


3. Homoskedasticity
Again, this can be checked with residual plots.
```{r message= FALSE, warning= FALSE}
plot(fitted(mod), residuals(mod))
```

4. Normality of residuals
```{r message= FALSE, warning= FALSE}
hist(residuals(mod))
qqnorm(residuals(mod))
```

5. Absence of influential data points
This assumption is met with visual investigation of violin boxplot.

6. Independence
This assumption is met with modeling (fixed effects: Valence cagetory, Language; random effects: Concreteness, Word Length). 


<!--chapter:end:03-visualisation.Rmd-->

`r if (knitr::is_html_output()) '
# References {-}
'`

<!--chapter:end:04-references.Rmd-->

