[["index.html", "Data analysis script Chapter 1 Overview", " Data analysis script Ibana Matsuo 2023-10-14 Chapter 1 Overview This webpage consists of the R script I used to conduct data cleaning, wrangling, visualisation, and statistical analysis for my MSc Dissertation project at the University of Glasgow. Dissertation Title: The Emotion Effect in First- and Second- Language Book Reading: Emotional Disembodiment or Attentional Advantage? Abstract Bilinguals emotion processing has emerged as an exciting area of research given the ubiquitous nature of bilingualism and the importance of language in emotion processing. Despite a growing consensus that written words are processed differently depending on their emotional valence, existing research on emotion and lexical processing has mostly been conducted with a single-word experimental paradigm. The present study analysed data from a bilingual corpus of eye movements while reading a novel to investigate processing differences among three valence categories (positive/negative/neutral) and between bilinguals L1 and L2 (Dutch/English). We found no processing differences among the valence categories in L1, which is contrary to the previous studies. Interestingly, the only processing advantage we found was in L2 positive words over neutral words. These findings suggest that valence may not exert a processing advantage when bilinguals read in L1, and that the disembodiment account of L2 may not explain the processing patterns in L2. The implications of these findings are discussed with a model of emotion and attentional resources and the emotionality of global narrative contexts, instead of individual words. "],["set-up-and-data-preparation.html", "Chapter 2 Set-up and Data preparation 2.1 Load libraries 2.2 Prepare GECO Material 2.3 Prepare Valence dataset 2.4 Prepare concreteness rating 2.5 Prepare list of Identical cognates 2.6 Combine prepared datasets to create target word lists 2.7 Categorise target words and remove unknown words 2.8 Create summary tables for WordLists 2.9 Visualisation of target word lists 2.10 Demographic information 2.11 Data wrangling on ReadingData 2.12 Join ReadingData and Target Word Lists 2.13 Detect outliers 2.14 Account for the repeated words in the datasets 2.15 Clean up repeating words in ReadingData 2.16 Summary of words for analysis 2.17 Mean centering 2.18 Summary of SFD", " Chapter 2 Set-up and Data preparation 2.1 Load libraries library(&quot;readxl&quot;) library(&quot;lme4&quot;) library(&quot;emmeans&quot;) library(&quot;broom.mixed&quot;) library(&quot;kableExtra&quot;) library(&quot;tidyverse&quot;) library(&quot;optimx&quot;) #optimx package for modelling 2.2 Prepare GECO Material GECO Materials are downloaded from Cop et al. (2017) https://expsy.ugent.be/downloads/geco/ EnglishMaterial_raw &lt;- read_excel(&quot;EnglishMaterial.xlsx&quot;) DutchMaterial_raw &lt;- read_excel(&quot;DutchMaterials.xlsx&quot;) I created Material tibbles (EnglishMaterial &amp; DutchMaterial) by only selecting necessary columns (Language, WORD_ID, WORD, PART_OF_SPEECH, CONTENT_WORD, WORD_LENGTH) and only content words. EnglishMaterial &lt;- EnglishMaterial_raw %&gt;% mutate(Language = &quot;English&quot;) %&gt;% select(Language, WORD_ID, WORD, PART_OF_SPEECH, CONTENT_WORD, WORD_LENGTH) %&gt;% filter(CONTENT_WORD == &quot;1&quot;) %&gt;% unique() DutchMaterial &lt;- DutchMaterial_raw %&gt;% mutate(Language = &quot;Dutch&quot;, WORD_ID = IA_ID) %&gt;% select(Language, WORD_ID, WORD, PART_OF_SPEECH, CONTENT_WORD, WORD_LENGTH) %&gt;% filter(CONTENT_WORD == &quot;1&quot;) %&gt;% unique() 2.3 Prepare Valence dataset Valence rating datasets are downloaded from http://crr.ugent.be/programs-data/word-ratings. Because two valence datasets use different rating metrics, I transformed valence ratings (V_Mean) to V_Mean_percent, ranging 0-1. close to 0 is negative, and close to 1 is positive. English Original rating by Warriner et al. (2013) is 1(happy) - 9(unhappy). The valence rating are already reversed post-hoc to maintain more intuitive low-to-high scale 1(unhappy) - 9(happy) (5 = neutral). Thus no need to reverse again. EnglishValence &lt;- read.csv(&quot;Ratings_Warriner_et_al.csv&quot;) In this dataset, Percent_known not collected. Number of contribution is stored as V.Rat.Sum in original dataset. EnglishValence &lt;- EnglishValence %&gt;% select(Word, V.Mean.Sum, V.SD.Sum) %&gt;% rename(WORD = Word, V_Mean = V.Mean.Sum, V_SD = V.SD.Sum) %&gt;% mutate(V_Mean_Percent = (V_Mean-1)/(9-1)) Dutch Original rating by Moors et al. (2013) is 1(unhappy) - 7(happy) (4 = neutral). DutchValence &lt;- read_excel(&quot;WordNorms Moors et al.xlsx&quot;, skip = 1) DutchValence &lt;- DutchValence %&gt;% select(Words, Translation, &#39;M V...3&#39;, &#39;SD V...4&#39;, &#39;N (%)&#39;) %&gt;% rename(WORD = Words, V_Mean = &#39;M V...3&#39;, V_SD = &#39;SD V...4&#39;, UnknownRatio = &#39;N (%)&#39;) %&gt;% mutate(V_Percent_known = (100 - UnknownRatio)/100, V_Mean_Percent = (V_Mean-1)/(7-1)) For DutchWords, we will remove any words which scores more than 30 on UnknownRatio c.f., less than 70% of participants knew the words The max of UnknownRation is zweems 26.9%, therefore include all words in analysis. 2.4 Prepare concreteness rating Two published concreteness ratings (Brysbaert, Stevens, et al., 2014 for Dutch; Brysbaert, Warriner, et al., 2014 for English) are used to include in a model as a control variable. English EnglishConcreteness &lt;- read_excel(&quot;Concreteness_ratings_Brysbaert_et_al_BRM.xlsx&quot;) EnglishConcreteness &lt;- EnglishConcreteness %&gt;% select(Word, Bigram, Conc.M, Conc.SD, Percent_known) %&gt;% rename(WORD = Word, Conc_Mean = Conc.M, Conc_SD = Conc.SD, C_Percent_known = Percent_known) %&gt;% filter(Bigram == &quot;0&quot;) %&gt;% #filter out two-word expressions (2896 out of 39954 words) select(-Bigram) Dutch read_excel() returned warning, thus I converted the excel file into csv file and used read_csv() function. DutchConcreteness &lt;- read_csv(&quot;Concreteness ratings Brysbaert et al.csv&quot;) DutchConcreteness &lt;- DutchConcreteness %&gt;% select(stimulus, Concrete_m, Concrete_sd, `Number_of_ratings`, Number_of_subjects) %&gt;% mutate(C_Percent_known = `Number_of_ratings`/ Number_of_subjects) %&gt;% select(stimulus, Concrete_m, Concrete_sd, C_Percent_known) %&gt;% rename(WORD = stimulus, Conc_Mean = Concrete_m, Conc_SD = Concrete_sd) In the original Dutch dataset, I found that there are 17 duplicate Dutch words with different concreteness ratings, making the number of words to 30070. DutchConcreteness_dup &lt;- DutchConcreteness %&gt;% subset(duplicated(WORD)) %&gt;% select(WORD) %&gt;% unique() %&gt;% mutate(Duplicate = &quot;1&quot;) #1 means Yes DutchConcreteness_dup2 &lt;- left_join(DutchConcreteness, DutchConcreteness_dup, &quot;WORD&quot;) %&gt;% mutate(Duplicate = replace_na(Duplicate, &quot;0&quot;)) %&gt;% filter(Duplicate == &quot;1&quot;) Now DutchConcreteness_dup contains 73 duplicate rows. Here are the steps I followed: 1) calculate the Conc_M means of each duplicate word, 2) make a list of 17 words with the mean Conc_M, then 3) replace it into final DutchConcreteness dataset. #1) calculate Mean of Conc_Mean for each duplicate word DutchConcreteness_dup2 &lt;- DutchConcreteness_dup2 %&gt;% group_by(WORD) %&gt;% mutate(Conc_Mean_M = mean(Conc_Mean)) %&gt;% ungroup() #2) make a list of 17 words DutchConcreteness_dup2 &lt;- DutchConcreteness_dup2 %&gt;% select(WORD, Conc_Mean_M) %&gt;% unique() %&gt;% rename(Conc_Mean = Conc_Mean_M) %&gt;% # add back Conc_SD and C_Percent_known columns to match up with the DutchConcreteness dataset mutate(Conc_SD = 1, C_Percent_known = 1, Duplicate = &quot;0&quot;) #0 means No #3) Replace it into final DutchConcreteness dataset DutchConcreteness_F &lt;- left_join(DutchConcreteness, DutchConcreteness_dup, &quot;WORD&quot;) %&gt;% mutate(Duplicate = replace_na(Duplicate, &quot;0&quot;)) %&gt;% filter(Duplicate == &quot;0&quot;) #0 means No #29997 words 29997+17=30014 words in the final tibble named DutchConcreteness. DutchConcreteness &lt;- bind_rows(DutchConcreteness_F, DutchConcreteness_dup2) %&gt;% select(-Duplicate) 2.5 Prepare list of Identical cognates We decided to exclude identical cognates as research shows that cognates are recognised and processed faster (i.e., cognates effect; Dijkstra et al. (2010)). Data is retrieved from Poort &amp; Rodd (2019) (https://osf.io/tcdxb/). DutchEnglishCognates &lt;- read_excel(&quot;PoortRodd.DatabaseOf58IdenticalCognates76Non-IdenticalCognates72InterlingualHomographs78TranslationEquivalents.xlsx&quot;, &#39;identical cognates&#39;) DutchEnglishCognates &lt;- DutchEnglishCognates %&gt;% select(word_NL, word_EN) %&gt;% mutate(WORD = word_EN, Cognate = &quot;1&quot;) %&gt;% # 1 means Yes select(WORD, Cognate) 2.6 Combine prepared datasets to create target word lists English I used inner_join() to combine English Material, Valence rating(independent variable), and concreteness rating(control variable). Then I used left_join() to add information of cognates. EnglishMaterialValence &lt;- inner_join(EnglishMaterial, EnglishValence, &quot;WORD&quot;) EnglishMaterialValConc &lt;- inner_join(EnglishMaterialValence, EnglishConcreteness, &quot;WORD&quot;) ##Cognates EnglishWordList_w_Cognate &lt;- left_join(EnglishMaterialValConc, DutchEnglishCognates, &quot;WORD&quot;) #EnglishCognateList &lt;- EnglishWordList_w_Cognate %&gt;% # filter(Cognate == &quot;1&quot;) #23 out of 2200 words are cognates to remove To determine whether I use inner_join() or left_join() to combine concreteness rating (control variable), I checked the number of words with no concreteness rating. With the below coding I found that only 24 out of 2224 words do not have concreteness rating, thus removing them would not affect the quality of final word list. #EnglishMaterialValenceConcreteness &lt;- left_join(EnglishMaterialValence, EnglishConcreteness, &quot;WORD&quot;) #24 out of 2224 words do not have concreteness rating -&gt; removing them would not affect the final word list Finally, I create EnglishWordList tibble by removing cognates. EnglishWordList &lt;- EnglishWordList_w_Cognate %&gt;% replace(is.na(.),&quot;0&quot;) %&gt;% filter(Cognate == &quot;0&quot;) Dutch Same as English, I checked the number of words with no concreteness rating to decide whether I use innter_join() or left_join() to add concreteness rating. With the below coding I found that 8 out of 1294 words do not have concreteness rating, thus removing them would not affect the quality of final word list. DutchMaterialValenceConcreteness &lt;- left_join(DutchMaterialValence, DutchConcreteness, &quot;WORD&quot;) #8 out of 1294 words do not have concreteness rating -&gt; removing them would not affect the final word list The below codes shows how I combined DutchMaterial, Valence rating(independent variable), and concreteness rating(control variable). DutchMaterialValence &lt;- inner_join(DutchMaterial, DutchValence, &quot;WORD&quot;) DutchMaterialValConc &lt;- inner_join(DutchMaterialValence, DutchConcreteness, &quot;WORD&quot;) ##Cognates DutchWordList_w_Cognate &lt;-left_join(DutchMaterialValConc, DutchEnglishCognates, &quot;WORD&quot;) #DutchCognateList &lt;- DutchWordList_w_Cognate %&gt;% # filter(Cognate == &quot;1&quot;) #14 out of 1286 words are cognates to remove Finally I created DutchWordList tibble by removing cognates. DutchWordList &lt;- DutchWordList_w_Cognate %&gt;% replace(is.na(.),&quot;0&quot;) %&gt;% filter(Cognate == &quot;0&quot;) 2.7 Categorise target words and remove unknown words At 2.3, I transformed two Valence ratings (English &amp; Dutch) to the normalised 0-1 scale (V_Mean_Percentage) so that two different likert scales (7-point &amp; 9-point) can be compared. I followed Toivo &amp; Scheepers (2019) regarding how to categorise words into three varence groups(Positive/Negative/Neutral); that is, based on the normalised scale, words with a valence rating under 0.33 were categorised as Negative, words with a valence rating over 0.66 were categorised as Positive, and the rest were categorised as Neutral. Also, words with &lt;75% KnownRatio are removed from the wordlists. Although there was no English words with lower than 85% known ratio, some Dutch words were applicable to this criteria thus removed from the final dataset. English EnglishWordList &lt;- EnglishWordList %&gt;% mutate(V_Category = case_when(V_Mean_Percent &gt; 0.66 ~ &quot;Positive&quot;, V_Mean_Percent &lt; 0.33 ~ &quot;Negative&quot;, TRUE ~ &quot;Neutral&quot;)) %&gt;% select(-CONTENT_WORD, -Cognate) Dutch DutchWordList &lt;- DutchWordList %&gt;% mutate(V_Category = case_when(V_Mean_Percent &gt; 0.66 ~ &quot;Positive&quot;, V_Mean_Percent &lt; 0.33 ~ &quot;Negative&quot;, TRUE ~ &quot;Neutral&quot;)) %&gt;% select(-CONTENT_WORD, -UnknownRatio, -Cognate) DutchWordList &lt;- DutchWordList %&gt;% filter(!(C_Percent_known &lt; 0.75)) 2.8 Create summary tables for WordLists I excluded WORD_ID and then select unique rows to summarise the characteristics of unique words in the target word lists. English EnglishWordList_noDup &lt;- EnglishWordList %&gt;% select(-WORD_ID) %&gt;% unique() Sum_EnglishWordList &lt;- EnglishWordList_noDup %&gt;% group_by(V_Category) %&gt;% summarise(N = n(), Mean_Valence_Percent = mean(V_Mean_Percent, na.rm = TRUE), SD_Valence_Percent = sd(V_Mean_Percent, na.rm = TRUE), Mean_WordLength = mean(WORD_LENGTH, na.rm = TRUE), SD_WordLength = sd(WORD_LENGTH, na.rm = TRUE), Mean_Conc = mean(Conc_Mean, na.rm = TRUE), SD_Conc = sd(Conc_Mean, na.rm = TRUE), Mean_KnownRatio = mean(C_Percent_known, na.rm = TRUE), #as there is no V_Percent_known data, using C_Percent_known SD_KnownRatio = sd(C_Percent_known, na.rm = TRUE)) %&gt;% ungroup() %&gt;% mutate(Language = &quot;English&quot;) Dutch DutchWordList_noDup &lt;- DutchWordList %&gt;% select(-WORD_ID) %&gt;% unique() Sum_DutchWordList &lt;- DutchWordList_noDup %&gt;% group_by(V_Category) %&gt;% summarise(N = n(), Mean_Valence_Percent = mean(V_Mean_Percent, na.rm = TRUE), SD_Valence_Percent = sd(V_Mean_Percent, na.rm = TRUE), Mean_WordLength = mean(WORD_LENGTH, na.rm = TRUE), SD_WordLength = sd(WORD_LENGTH, na.rm = TRUE), Mean_Conc = mean(Conc_Mean, na.rm = TRUE), SD_Conc = sd(Conc_Mean, na.rm = TRUE), Mean_KnownRatio = mean(C_Percent_known, na.rm = TRUE), #C_Percent_known to match w/ English though V_Percent_known is available SD_KnownRatio = sd(C_Percent_known, na.rm = TRUE)) %&gt;% ungroup() %&gt;% mutate(Language = &quot;Dutch&quot;) Summary I combined two summary tables. Note that this table describes the characteristics of the words in the target word list, which is created with ReadingMaterial = the words in the novel. The target word list will be compared with ReadingData, which contains the eye-tracking data generated in the experiment. Sum_WordList &lt;- bind_rows(Sum_DutchWordList,Sum_EnglishWordList) df_Sum_WordList &lt;- as.data.frame(Sum_WordList) wordsummary &lt;- data.frame(df_Sum_WordList$Language, df_Sum_WordList$V_Category, df_Sum_WordList$N, round(df_Sum_WordList$Mean_Valence_Percent,3), round(df_Sum_WordList$SD_Valence_Percent,3), round(df_Sum_WordList$Mean_WordLength,2), round(df_Sum_WordList$SD_WordLength,2), round(df_Sum_WordList$Mean_Conc,2), round(df_Sum_WordList$SD_Conc,2), round(df_Sum_WordList$Mean_KnownRatio,3), round(df_Sum_WordList$SD_KnownRatio,3)) names(wordsummary) &lt;- (c(&quot;Language&quot;, &quot;Valence Category&quot;, &quot;N&quot;, &quot;Valence rating (Mean)&quot;, &quot;Valence rating (SD)&quot;, &quot;Word Length (Mean)&quot;, &quot;Word Length (SD)&quot;, &quot;Concreteness rating (Mean)&quot;, &quot;Concreteness rating (SD)&quot;, &quot;Word known ratio (Mean)&quot;, &quot;Word known ratio (SD)&quot;)) kable(wordsummary) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;200px&quot;) Language Valence Category N Valence rating (Mean) Valence rating (SD) Word Length (Mean) Word Length (SD) Concreteness rating (Mean) Concreteness rating (SD) Word known ratio (Mean) Word known ratio (SD) Dutch Negative 210 0.235 0.065 6.86 2.32 2.60 0.79 0.997 0.013 Dutch Neutral 754 0.516 0.085 5.28 1.63 3.39 1.06 0.996 0.021 Dutch Positive 289 0.764 0.068 6.54 2.40 2.48 0.87 0.999 0.014 English Negative 319 0.234 0.063 7.03 2.23 2.73 0.83 0.994 0.019 English Neutral 1300 0.528 0.085 6.48 2.32 3.20 1.06 0.994 0.019 English Positive 558 0.744 0.060 6.81 2.37 2.89 1.04 0.998 0.010 2.9 Visualisation of target word lists For the reference, I created histograms for valence ratings of the target words. From the histogram, you can see that 1) English valence rating seems negatively skewed, and 2) Dutch valence rating seems normally distributed. English ggplot(EnglishWordList_noDup, aes(V_Mean_Percent)) + geom_histogram(binwidth = .01, colour = &quot;black&quot;, fill = &quot;grey&quot;, aes(y = ..density..)) + scale_x_continuous(name = &quot;English Mean Valence (0-1)&quot;) + stat_function(fun = dnorm, # this adds a normal density function curve colour = &quot;red&quot;, # this makes it red args = list(mean = mean(EnglishWordList_noDup$V_Mean_Percent, na.rm = TRUE), sd = sd(EnglishWordList_noDup$V_Mean_Percent, na.rm = TRUE))) Dutch ggplot(DutchWordList_noDup, aes(V_Mean_Percent)) + geom_histogram(binwidth = .01, colour = &quot;black&quot;, fill = &quot;grey&quot;, aes(y = ..density..)) + scale_x_continuous(name = &quot;Dutch Mean Valence (0-1)&quot;) + stat_function(fun = dnorm, # this adds a normal density function curve colour = &quot;red&quot;, # this makes it red args = list(mean = mean(DutchWordList_noDup$V_Mean_Percent, na.rm = TRUE), sd = sd(DutchWordList_noDup$V_Mean_Percent, na.rm = TRUE))) 2.10 Demographic information First of all, I loaded the dataset and selected only necessary information. One participant(pp18) was removed from the dataset because they only read first half of the book in English (Cop et al., 2017). #Load the dataset Demographic &lt;- read_excel(&quot;SubjectInformation.xlsx&quot;) #Select necessary information. Demographic &lt;- Demographic %&gt;% select(PP_NR, GROUP, AGE, SEX, AOA_ENG) %&gt;% filter(GROUP == &quot;bilingual&quot;) %&gt;% mutate(PP_NR_N = recode(PP_NR, #Change PP_NR label to match with ReadingData &quot;1&quot; = &quot;pp01&quot;, &quot;2&quot; = &quot;pp02&quot;, &quot;3&quot; = &quot;pp03&quot;, &quot;4&quot; = &quot;pp04&quot;, &quot;5&quot; = &quot;pp05&quot;, &quot;6&quot; = &quot;pp06&quot;, &quot;7&quot; = &quot;pp07&quot;, &quot;8&quot; = &quot;pp08&quot;, &quot;9&quot; = &quot;pp09&quot;, &quot;10&quot; = &quot;pp10&quot;, &quot;11&quot; = &quot;pp11&quot;, &quot;12&quot; = &quot;pp12&quot;, &quot;13&quot; = &quot;pp13&quot;, &quot;14&quot; = &quot;pp14&quot;, &quot;15&quot; = &quot;pp15&quot;, &quot;16&quot; = &quot;pp16&quot;, &quot;17&quot; = &quot;pp17&quot;, &quot;18&quot; = &quot;pp18&quot;, &quot;19&quot; = &quot;pp19&quot;)) %&gt;% select(PP_NR_N, GROUP, AGE, SEX, AOA_ENG) %&gt;% rename(PP_NR = PP_NR_N) %&gt;% filter(!(PP_NR == &quot;pp18&quot;)) #remove pp18 Demographic information is summarised in the Demographic_table tibble. Demographic_table &lt;- Demographic %&gt;% summarise(N = n(), MAge = mean(AGE, na.rm = TRUE), SDAge = sd(AGE, na.rm = TRUE), MAoA = mean(AOA_ENG, na.rm = TRUE), SDAoA = sd(AOA_ENG, na.rm = TRUE)) kable(Demographic_table) %&gt;% kable_styling() N MAge SDAge MAoA SDAoA 18 21.11111 2.138963 11.11111 2.44682 2.11 Data wrangling on ReadingData Here I uploaded the ReadingData from GECO project (Cop et al., 2017), retrieved from https://expsy.ugent.be/downloads/geco/. EnglishReadingData_raw &lt;- read_excel(&quot;L2ReadingData.xlsx&quot;) DutchReadingData_raw &lt;- read_excel(&quot;L1ReadingData.xlsx&quot;) English I first worked on EnglishReadingData. For the analyses, I selected PP_NR, PART, WORD, WORD_FIXATION_COUNT, WORD_FIRST_FIXATION_DURATION. Single Fixation Duration (SFD) is our dependent variables which are the Words that has WORD_FIXATION_COUNT = 1. EnglishReadingData &lt;- EnglishReadingData_raw %&gt;% select(PP_NR, PART, WORD_ID, WORD, WORD_FIXATION_COUNT, WORD_FIRST_FIXATION_DURATION) %&gt;% filter(WORD_FIXATION_COUNT == &quot;1&quot;, !(PP_NR == &quot;pp18&quot;)) #pp18 is removed as this participant only completed half of the experiment The reading data contains punctuation, which needs to be removed so that we can combine the reading data with target wordlists. EnglishReadingData_Final &lt;- EnglishReadingData %&gt;% mutate(WORD2 = lapply(WORD, function(x) {str_replace_all(x,&quot;[,.&#39;?!:;-]&quot;,&quot;&quot;)})) #Remove ,.&#39;?! from WORD and keep the results in WORD2 EnglishReadingData_Final$WORD3 &lt;- gsub(x=EnglishReadingData_Final$WORD2, pattern =&quot;\\&quot;&quot;, &quot;&quot;) #Remove &quot;&quot; from WORD2 and keep the results in WORD3 EnglishReadingData_Final &lt;- EnglishReadingData_Final %&gt;% select(PP_NR, PART, WORD_ID, WORD3, WORD_FIXATION_COUNT, WORD_FIRST_FIXATION_DURATION) %&gt;% rename(WORD = WORD3) %&gt;% mutate(WORD_FIRST_FIXATION_DURATION = as.numeric(WORD_FIRST_FIXATION_DURATION)) Dutch Same cleaning process as English is required for Dutch reading data. DutchReadingData &lt;- DutchReadingData_raw %&gt;% select(PP_NR, PART, WORD_ID, WORD, WORD_FIXATION_COUNT, WORD_FIRST_FIXATION_DURATION) %&gt;% filter(WORD_FIXATION_COUNT == &quot;1&quot;) DutchReadingData_Final &lt;- DutchReadingData %&gt;% mutate(WORD2 = lapply(WORD, function(x) {str_replace_all(x,&quot;[,.&#39;?!:;-]&quot;,&quot;&quot;)})) DutchReadingData_Final$WORD3 &lt;- gsub(x=DutchReadingData_Final$WORD2, pattern =&quot;\\&quot;&quot;, &quot;&quot;) DutchReadingData_Final &lt;- DutchReadingData_Final %&gt;% select(PP_NR, PART, WORD_ID, WORD3, WORD_FIXATION_COUNT, WORD_FIRST_FIXATION_DURATION) %&gt;% rename(WORD = WORD3) %&gt;% mutate(WORD_FIRST_FIXATION_DURATION = as.numeric(WORD_FIRST_FIXATION_DURATION)) 2.12 Join ReadingData and Target Word Lists We used WORD_ID to join the two tibbles. English There are 55737 words after the ReadingData_Final is compared against the target word list. EnglishReadingData_w_WordList &lt;- inner_join(EnglishReadingData_Final, EnglishWordList, &quot;WORD_ID&quot;) %&gt;% select(-WORD.y) %&gt;% rename(WORD = WORD.x) Dutch There are 47333 words after the ReadingData_Final is compared against the target word list. DutchReadingData_w_WordList &lt;- inner_join(DutchReadingData_Final,DutchWordList, &quot;WORD_ID&quot;) %&gt;% select(-WORD.y, -Translation, -V_Percent_known) %&gt;% rename(WORD = WORD.x) 2.13 Detect outliers Single Fixation Duration (SFD) that differed more than 2.5 standard deviations from the subject means were considered outliers and excluded from the dataset. English SubjectMeanSFD_EN &lt;- EnglishReadingData_w_WordList %&gt;% group_by(PP_NR) %&gt;% summarise(SFDSubjectMean = mean(WORD_FIRST_FIXATION_DURATION, na.rm = TRUE), SFDSubjectSD = sd(WORD_FIRST_FIXATION_DURATION, na.rm = TRUE)) %&gt;% ungroup() EnglishReadingData_w_WordList &lt;- inner_join(EnglishReadingData_w_WordList, SubjectMeanSFD_EN, &quot;PP_NR&quot;) EnglishReadingData_w_WordList_Outlier &lt;- EnglishReadingData_w_WordList %&gt;% mutate(Outlier = case_when(WORD_FIRST_FIXATION_DURATION &gt; SFDSubjectMean + (SFDSubjectSD * 2.5) ~ &quot;1&quot;, WORD_FIRST_FIXATION_DURATION &lt; SFDSubjectMean - (SFDSubjectSD * 2.5) ~ &quot;1&quot;, TRUE ~ &quot;0&quot;)) # Outliers if 1 EnglishReadingData_w_WordList &lt;- EnglishReadingData_w_WordList_Outlier %&gt;% filter(Outlier == &quot;0&quot;) According to the summary created below, 1,189 of 55,737 items are identified as outliers in EnglishReadingData. Sum_Outlier_EN &lt;- EnglishReadingData_w_WordList_Outlier %&gt;% group_by(Outlier) %&gt;% summarise(n = n()) %&gt;% ungroup() Sum_Outlier_EN ## # A tibble: 2 x 2 ## Outlier n ## &lt;chr&gt; &lt;int&gt; ## 1 0 54548 ## 2 1 1189 Dutch SubjectMeanSFD_NL &lt;- DutchReadingData_w_WordList %&gt;% group_by(PP_NR) %&gt;% summarise(SFDSubjectMean = mean(WORD_FIRST_FIXATION_DURATION, na.rm = TRUE), SFDSubjectSD = sd(WORD_FIRST_FIXATION_DURATION, na.rm = TRUE)) %&gt;% ungroup() DutchReadingData_w_WordList &lt;- inner_join(DutchReadingData_w_WordList, SubjectMeanSFD_NL, &quot;PP_NR&quot;) DutchReadingData_w_WordList_Outlier &lt;- DutchReadingData_w_WordList %&gt;% mutate(Outlier = case_when(WORD_FIRST_FIXATION_DURATION &gt; SFDSubjectMean + (SFDSubjectSD * 2.5) ~ &quot;1&quot;, WORD_FIRST_FIXATION_DURATION &lt; SFDSubjectMean - (SFDSubjectSD * 2.5) ~ &quot;1&quot;, TRUE ~ &quot;0&quot;)) # Outliers if 1 DutchReadingData_w_WordList &lt;- DutchReadingData_w_WordList_Outlier %&gt;% filter(Outlier == &quot;0&quot;) According to the summary created below, 1,000 of 47,333 items are identified as outliers in DutchReadingData. Sum_Outlier_NL &lt;- DutchReadingData_w_WordList_Outlier %&gt;% group_by(Outlier) %&gt;% summarise(n = n()) %&gt;% ungroup() Sum_Outlier_NL ## # A tibble: 2 x 2 ## Outlier n ## &lt;chr&gt; &lt;int&gt; ## 1 0 46333 ## 2 1 1000 2.14 Account for the repeated words in the datasets Repeated words refer to the target words that are repeated multiple times in the ReadingData (e.g., that in English). Here, I added a new column that flags if the target words are repeated in the ReadingData dataset. English According to the below summary, there are 18005 target words in reading dataset, in which 8037 words are repeated. That means, 44.64% of words are repeated with a range of 2-129 times. Sum_EnglishReadingData_w_WordList &lt;- EnglishReadingData_w_WordList %&gt;% group_by(PP_NR, WORD) %&gt;% summarise(N = n()) %&gt;% ungroup() %&gt;% mutate(Repeated = case_when(N &gt; 1 ~ &quot;1&quot;, TRUE ~&quot;0&quot;)) count(Sum_EnglishReadingData_w_WordList, Repeated == &quot;0&quot;) ## # A tibble: 2 x 2 ## `Repeated == &quot;0&quot;` n ## &lt;lgl&gt; &lt;int&gt; ## 1 FALSE 8037 ## 2 TRUE 9968 I created visualisation to find characteristics of these repeated words. Here you can see that most of repeated words are only repeated twice or three times. Sum2_EnglishReadingData_w_WordList &lt;- Sum_EnglishReadingData_w_WordList %&gt;% filter(Repeated == &quot;1&quot;) ggplot(Sum2_EnglishReadingData_w_WordList, aes(N)) + geom_bar() Dutch According to the below summary, there are 11487 target words in reading dataset, in which 5933 words are repeated. That means, 51.65% of words are repeated with a range of 2-253 times. Sum_DutchReadingData_w_WordList &lt;- DutchReadingData_w_WordList %&gt;% group_by(PP_NR, WORD) %&gt;% summarise(N = n()) %&gt;% ungroup() %&gt;% mutate(Repeated = case_when(N &gt; 1 ~ &quot;1&quot;, TRUE ~&quot;0&quot;)) count(Sum_DutchReadingData_w_WordList, Repeated == &quot;0&quot;) ## # A tibble: 2 x 2 ## `Repeated == &quot;0&quot;` n ## &lt;lgl&gt; &lt;int&gt; ## 1 FALSE 5933 ## 2 TRUE 5554 Visualisations are created for Dutch data as well. Same as English data, you can see that most of repeated words are only repeated twice or three times. Sum2_DutchReadingData_w_WordList &lt;- Sum_DutchReadingData_w_WordList %&gt;% filter(Repeated == &quot;1&quot;) #Most of repeated words only repeated twice/three times ggplot(Sum2_DutchReadingData_w_WordList, aes(N)) + geom_bar() 2.15 Clean up repeating words in ReadingData Based on the analysis at 2.14, we concluded that the word proportion of repeated words is not significant (= less than 80%). Thus, we keep only the first instance of each of the repeating words per participant for our analysis. Here I used slice(1) to select the first row. slice_head() would also work. If want random selection, slice_sample() can be used instead of slice(#) or slice_head(). English EnglishReadingData_w_WordList_NoRep &lt;- EnglishReadingData_w_WordList %&gt;% group_by(PP_NR, WORD) %&gt;% slice(1) %&gt;% ungroup() Dutch DutchReadingData_w_WordList_NoRep &lt;- DutchReadingData_w_WordList %&gt;% group_by(PP_NR, WORD) %&gt;% slice(1) %&gt;% ungroup() 2.16 Summary of words for analysis ReadingData_raw contains 549,290 words for Dutch and 534,154 words for English. After selecting SFD and compared against our target word list, the number of words is 47,333 (Dutch) and 55,737 (English), which is 9.51% of the raw data. Then we selected only one appearance per word per person, which made the number of words for our analysis 11,487 (Dutch) and 18,005 (English), 2.72% of the raw data. I created a summary table of the words in ReadingData dataset that are analysed in the current study. ReadingData_w_WordList_NoRep &lt;- bind_rows(EnglishReadingData_w_WordList_NoRep, DutchReadingData_w_WordList_NoRep) Sum_ReadingData_ENandNL &lt;- ReadingData_w_WordList_NoRep %&gt;% select(Language, V_Category, V_Mean_Percent, WORD_LENGTH, Conc_Mean, C_Percent_known) %&gt;% group_by(Language, V_Category) %&gt;% summarise(N = n(), Mean_Valence_Percent = mean(V_Mean_Percent, na.rm = TRUE), SD_Valence_Percent = sd(V_Mean_Percent, na.rm = TRUE), Mean_WordLength = mean(WORD_LENGTH, na.rm = TRUE), SD_WordLength = sd(WORD_LENGTH, na.rm = TRUE), Mean_Conc = mean(Conc_Mean, na.rm = TRUE), SD_Conc = sd(Conc_Mean, na.rm = TRUE), Mean_KnownRatio = mean(C_Percent_known, na.rm = TRUE), SD_KnownRatio = sd(C_Percent_known, na.rm = TRUE)) %&gt;% ungroup() df_Sum_ReadingData &lt;- as.data.frame(Sum_ReadingData_ENandNL) ReadingDataSummary &lt;- data.frame(df_Sum_ReadingData$Language, df_Sum_ReadingData$V_Category, df_Sum_ReadingData$N, round(df_Sum_ReadingData$Mean_Valence_Percent,2), round(df_Sum_ReadingData$SD_Valence_Percent,2), round(df_Sum_ReadingData$Mean_WordLength,2), round(df_Sum_ReadingData$SD_WordLength,2), round(df_Sum_ReadingData$Mean_Conc,2), round(df_Sum_ReadingData$SD_Conc,2), round(df_Sum_ReadingData$Mean_KnownRatio,3), round(df_Sum_ReadingData$SD_KnownRatio,3)) names(ReadingDataSummary) &lt;- (c(&quot;Language&quot;, &quot;Valence Category&quot;, &quot;N&quot;, &quot;Valence rating (Mean)&quot;, &quot;Valence rating (SD)&quot;, &quot;Word Length (Mean)&quot;, &quot;Word Length (SD)&quot;, &quot;Concreteness rating (Mean)&quot;, &quot;Concreteness rating (SD)&quot;, &quot;Word known ratio (Mean)&quot;, &quot;Word known ratio (SD)&quot;)) kable(ReadingDataSummary) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;100%&quot;) Language Valence Category N Valence rating (Mean) Valence rating (SD) Word Length (Mean) Word Length (SD) Concreteness rating (Mean) Concreteness rating (SD) Word known ratio (Mean) Word known ratio (SD) Dutch Negative 1713 0.24 0.07 6.71 2.25 2.64 0.78 0.998 0.012 Dutch Neutral 7072 0.52 0.08 5.27 1.57 3.36 1.07 0.996 0.021 Dutch Positive 2702 0.76 0.07 6.31 2.29 2.48 0.89 0.999 0.013 English Negative 2433 0.23 0.06 6.59 2.14 2.81 0.85 0.995 0.015 English Neutral 10445 0.53 0.08 5.97 2.10 3.27 1.05 0.995 0.017 English Positive 5127 0.74 0.06 6.39 2.25 2.97 1.07 0.998 0.009 Here I also summarised the number of items per participant per language. Sum_ReadingData_ENandNL_itemsperparticipants &lt;- ReadingData_w_WordList_NoRep %&gt;% group_by(PP_NR, Language) %&gt;% summarise(N = n()) %&gt;% ungroup() kable(Sum_ReadingData_ENandNL_itemsperparticipants) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;500px&quot;) PP_NR Language N pp01 Dutch 669 pp01 English 990 pp02 Dutch 627 pp02 English 1076 pp03 Dutch 642 pp03 English 1007 pp04 Dutch 617 pp04 English 1106 pp05 Dutch 663 pp05 English 981 pp06 Dutch 660 pp06 English 879 pp07 Dutch 669 pp07 English 1041 pp08 Dutch 651 pp08 English 1001 pp09 Dutch 643 pp09 English 952 pp10 Dutch 621 pp10 English 1053 pp11 Dutch 661 pp11 English 1097 pp12 Dutch 640 pp12 English 1110 pp13 Dutch 615 pp13 English 860 pp14 Dutch 620 pp14 English 1099 pp15 Dutch 629 pp15 English 885 pp16 Dutch 586 pp16 English 1036 pp17 Dutch 649 pp17 English 786 pp19 Dutch 625 pp19 English 1046 2.17 Mean centering All continuous variable will be centred to reduce collinearity between main effects and interactions: WORD_FIRST_FIXATION_DURATION, WORD_LENGTH, Conc_Mean. When you have continuous variables in a regression, it is often sensible to transform them by mean centering. You mean center a predictor X simply by subtracting the mean (X_centered = X - mean(X)). This has two useful consequences: https://psyteachr.github.io/msc-conv/multiple-regression.html ReadingData_ENandNL &lt;- ReadingData_w_WordList_NoRep %&gt;% select(-WORD_FIXATION_COUNT, -V_SD, -Conc_SD,-C_Percent_known, -SFDSubjectMean, - SFDSubjectSD, -Outlier) %&gt;% #Cleaning up the tibble by removing columns that are no longer required for analysis mutate(WORD_FIRST_FIXATION_DURATION_centered = WORD_FIRST_FIXATION_DURATION - mean(WORD_FIRST_FIXATION_DURATION), WORD_LENGTH_centered = WORD_LENGTH - mean(WORD_LENGTH), Conc_Mean_centered = Conc_Mean - mean(Conc_Mean)) 2.18 Summary of SFD Summary of Single Fixation Duration is also created as below. Sum_SFD &lt;- ReadingData_ENandNL %&gt;% group_by(V_Category, Language) %&gt;% summarise(Mean = mean(WORD_FIRST_FIXATION_DURATION), SD = sd(WORD_FIRST_FIXATION_DURATION)) %&gt;% ungroup() df_Sum_SFD &lt;- as.data.frame(Sum_SFD) SFDsummary &lt;- data.frame(df_Sum_SFD$Language, df_Sum_SFD$V_Category, round(df_Sum_SFD$Mean,2), round(df_Sum_SFD$SD,2)) names(SFDsummary) &lt;- (c(&quot;Language&quot;, &quot;Valence Category&quot;, &quot;SFD (Mean)&quot;, &quot;SFD (SD)&quot;)) Sum_SFDwoLang &lt;- ReadingData_ENandNL %&gt;% group_by(V_Category) %&gt;% summarise(Mean = mean(WORD_FIRST_FIXATION_DURATION), SD = sd(WORD_FIRST_FIXATION_DURATION)) %&gt;% ungroup() df_Sum_SFDwoLang &lt;- as.data.frame(Sum_SFDwoLang) SFDsummary_woLang &lt;- data.frame(df_Sum_SFDwoLang$V_Category, round(df_Sum_SFDwoLang$Mean,2), round(df_Sum_SFDwoLang$SD,2)) names(SFDsummary_woLang) &lt;- (c(&quot;Valence Category&quot;, &quot;SFD (Mean)&quot;, &quot;SFD (SD)&quot;)) kable(SFDsummary) %&gt;% kable_styling() Language Valence Category SFD (Mean) SFD (SD) Dutch Negative 209.06 70.60 English Negative 235.18 83.34 Dutch Neutral 204.38 69.85 English Neutral 232.73 82.78 Dutch Positive 205.37 70.08 English Positive 228.92 82.59 kable(SFDsummary_woLang) %&gt;% kable_styling() Valence Category SFD (Mean) SFD (SD) Negative 224.39 79.37 Neutral 221.29 79.05 Positive 220.79 79.29 References Brysbaert, M., Stevens, M., De Deyne, S., Voorspoels, W., &amp; Storms, G. (2014). Norms of age of acquisition and concreteness for 30,000 Dutch words. Acta Psychologica, 150, 8084. https://doi.org/10.1016/j.actpsy.2014.04.010 Brysbaert, M., Warriner, A. B., &amp; Kuperman, V. (2014). Concreteness ratings for 40 thousand generally known English word lemmas. Behavior Research Methods, 46(3), 904911. https://doi.org/10.3758/s13428-013-0403-5 Cop, U., Dirix, N., Drieghe, D., &amp; Duyck, W. (2017). Presenting GECO: An eyetracking corpus of monolingual and bilingual sentence reading. Behavior Research Methods, 49(2), 602615. https://doi.org/10.3758/s13428-016-0734-0 Dijkstra, T., Miwa, K., Brummelhuis, B., Sappelli, M., &amp; Baayen, H. (2010). How cross-language similarity and task demands affect cognate recognition. Journal of Memory and Language, 62(3), 284301. https://doi.org/10.1016/j.jml.2009.12.003 Moors, A., De Houwer, J., Hermans, D., Wanmaker, S., Schie, K. van, Van Harmelen, A.-L., De Schryver, M., De Winne, J., &amp; Brysbaert, M. (2013). Norms of valence, arousal, dominance, and age of acquisition for 4,300 Dutch words. Behavior Research Methods, 45(1), 169177. https://doi.org/10.3758/s13428-012-0243-8 Poort, E. D., &amp; Rodd, J. M. (2019). A Database of DutchEnglish Cognates, Interlingual Homographs and Translation Equivalents. Journal of Cognition, 2(1). https://doi.org/10.5334/joc.67 Toivo, W., &amp; Scheepers, C. (2019). Pupillary responses to affective words in bilinguals first versus second language. PLOS ONE, 14(4), e0210450. https://doi.org/10.1371/journal.pone.0210450 Warriner, A. B., Kuperman, V., &amp; Brysbaert, M. (2013). Norms of valence, arousal, and dominance for 13,915 English lemmas. Behavior Research Methods, 45(4), 11911207. https://doi.org/10.3758/s13428-012-0314-x "],["statistical-analysis.html", "Chapter 3 Statistical Analysis 3.1 Deviation coding and dummy coding 3.2 Find a best-fit model 3.3 Run model comparison for the main effect and interactions 3.4 Decompose the significant effects of valence 3.5 Expolatory analysis: compare positive vs negative 3.6 Decompose the non-significant effect of interaction", " Chapter 3 Statistical Analysis 3.1 Deviation coding and dummy coding Deviation coding are conducted for Language(independent variable) and valence rating(independent variable). We also conducted dummy coding for valence categories in case that interactions are significant and needed to be decomposed to detect single effect. #Deviation coding ReadingData_ENandNL &lt;- ReadingData_ENandNL %&gt;% mutate(Language_dev = if_else(Language == &quot;Dutch&quot;, .5, -.5), V_Category_NeuPos_dev = if_else(V_Category == &quot;Positive&quot;, 2/3, -1/3), V_Category_NeuNeg_dev = if_else(V_Category == &quot;Negative&quot;, 2/3, -1/3)) #Dummy coding ReadingData_ENandNL &lt;- ReadingData_ENandNL %&gt;% mutate(V_Category_NeuPos_dum = if_else(V_Category == &quot;Positive&quot;, 1, 0), V_Category_NeuNeg_dum = if_else(V_Category == &quot;Negative&quot;, 1, 0)) 3.2 Find a best-fit model SFD(dependent variable) is skewed, thus we decided to use glmer() to perform generalised linear mixed-effect model (GLMM). Here I left the coding for crafting models from simple to complex. #random effects (interception) #Step A simple model with Gamma model. #I did not use the mean-centered variables as it gave me error message. #mod &lt;- glmer(WORD_FIRST_FIXATION_DURATION ~ # #Main effects # V_Category_NeuPos_dev + # V_Category_NeuNeg_dev + # Language_dev + # #Control variables # WORD_LENGTH + # Conc_Mean + # #Interactions # V_Category_NeuPos_dev:Language_dev + # V_Category_NeuNeg_dev:Language_dev + # #Random effects # (1|WORD)+ (1|PP_NR), data = ReadingData_ENandNL, family = Gamma(link=&quot;identity&quot;)) #Step B: start adding slopes #mod3 &lt;- glmer(WORD_FIRST_FIXATION_DURATION~ # #Main effects # V_Category_NeuPos_dev + # V_Category_NeuNeg_dev + # Language_dev + # #Control variables # WORD_LENGTH + # Conc_Mean + # #Interactions # V_Category_NeuPos_dev:Language_dev + # V_Category_NeuNeg_dev:Language_dev + # #Random effects # (1|WORD)+ (1 + Language_dev + V_Category_NeuPos_dev + V_Category_NeuNeg_dev | PP_NR), data = ReadingData_ENandNL, family=Gamma(link=&quot;identity&quot;)) #Added random slope to WORD as well as PP_NR #mod4 &lt;- glmer(WORD_FIRST_FIXATION_DURATION~ # #Main effects # V_Category_NeuPos_dev + # V_Category_NeuNeg_dev + # Language_dev + # #Control variables # WORD_LENGTH + # Conc_Mean + # #Interactions # V_Category_NeuPos_dev:Language_dev + # V_Category_NeuNeg_dev:Language_dev + # #Random effects # (1 + Language_dev + V_Category_NeuPos_dev + V_Category_NeuNeg_dev |WORD)+ (1 + Language_dev + V_Category_NeuPos_dev + V_Category_NeuNeg_dev | PP_NR), # data = ReadingData_ENandNL, family=Gamma(link=&quot;identity&quot;)) #Step C: Maximal model #mod5 &lt;- glmer(WORD_FIRST_FIXATION_DURATION ~ # #Main effects # V_Category_NeuPos_dev + # V_Category_NeuNeg_dev + # Language_dev + # #Control variables # WORD_LENGTH + # Conc_Mean + # #Interactions # V_Category_NeuPos_dev:Language_dev + # V_Category_NeuNeg_dev:Language_dev + # #Random effects # (1|WORD)+ (1+Language_dev + V_Category_NeuPos_dev +V_Category_NeuNeg_dev + Conc_Mean + WORD_LENGTH | PP_NR), # data = ReadingData_ENandNL, family=Gamma(link=&quot;identity&quot;)) After running multiple models, I decided to go for a maxibal model which includes random slopes and intercepts for both participants and words (subjects and items). This serves as our baseline model = mod. mod &lt;- glmer(WORD_FIRST_FIXATION_DURATION ~ #Main effects V_Category_NeuPos_dev + V_Category_NeuNeg_dev + Language_dev + #Control variables Conc_Mean + WORD_LENGTH + #Interactions V_Category_NeuPos_dev:Language_dev + V_Category_NeuNeg_dev:Language_dev + #Random effects (1 + Language_dev + V_Category_NeuPos_dev + V_Category_NeuNeg_dev + Conc_Mean + WORD_LENGTH | WORD)+ (1 + Language_dev + V_Category_NeuPos_dev + V_Category_NeuNeg_dev + Conc_Mean + WORD_LENGTH | PP_NR), data = ReadingData_ENandNL, family=Gamma(link=&quot;identity&quot;), control = glmerControl(optimizer = &quot;optimx&quot;, calc.derivs = FALSE, optCtrl = list(method = &quot;L-BFGS-B&quot;, maxit = 10000, starttests = FALSE, kkt = FALSE))) save(mod,file=&#39;C:/Users/ibana/OneDrive - University of Glasgow/@Year 3/For Publication/Data and Code/mod_results.RData&#39;) Here I also created a baseline model with original categorical variables; that is, non-deviation coded variables are used for mod2. mod2 &lt;- glmer(WORD_FIRST_FIXATION_DURATION ~ #Main effects V_Category + Language + #Control variables Conc_Mean + WORD_LENGTH + #Interactions V_Category:Language + #Random effects (1 + Language + V_Category + Conc_Mean + WORD_LENGTH | WORD)+ (1 + Language + V_Category + Conc_Mean + WORD_LENGTH | PP_NR), data = ReadingData_ENandNL, family=Gamma(link=&quot;identity&quot;), control = glmerControl(optimizer = &quot;optimx&quot;, calc.derivs = FALSE, optCtrl = list(method = &quot;L-BFGS-B&quot;, maxit = 10000, starttests = FALSE, kkt = FALSE))) save(mod2,file=&#39;C:/Users/ibana/OneDrive - University of Glasgow/@Year 3/For Publication/Data and Code/mod2_results.RData&#39;) I created the summary of the model for reporting. modelsummary&lt;- broom.mixed::tidy(mod, effects = c(&quot;ran_pars&quot;, &quot;fixed&quot;),scales = NULL, ran_prefix = NULL, conf.int = TRUE, conf.level = 0.95, conf.method = &quot;Wald&quot;) %&gt;% filter(effect ==&quot;fixed&quot;) df_modelsummary &lt;- as.data.frame(modelsummary) modelsummary &lt;- data.frame(df_modelsummary$term, round(df_modelsummary$estimate,2), round(df_modelsummary$std.error,2), round(df_modelsummary$statistic,2), round(df_modelsummary$p.value,2), round(df_modelsummary$conf.low,2), round(df_modelsummary$conf.high,2)) names(modelsummary) &lt;- (c(&quot;Term&quot;, &quot;Estimate&quot;, &quot;Standard Error&quot;, &quot;t-value&quot;, &quot;p-value&quot;, &quot;95% CI (Lower)&quot;, &quot;95% CI (Higher)&quot;)) modelsummary$`p-value` &lt;- ifelse(modelsummary$`p-value` &lt;0.001, &quot;&lt;0.001&quot;, round(modelsummary$`p-value`, 3)) kable(modelsummary) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;100%&quot;) Term Estimate Standard Error t-value p-value 95% CI (Lower) 95% CI (Higher) (Intercept) 198.35 3.76 52.76 &lt;0.001 190.98 205.72 V_Category_NeuPos_dev -5.44 1.41 -3.85 &lt;0.001 -8.21 -2.67 V_Category_NeuNeg_dev -0.26 1.71 -0.15 0.88 -3.62 3.10 Language_dev -30.62 2.19 -13.96 &lt;0.001 -34.92 -26.32 Conc_Mean 0.32 0.63 0.51 0.61 -0.92 1.56 WORD_LENGTH 4.75 0.42 11.27 &lt;0.001 3.92 5.57 V_Category_NeuPos_dev:Language_dev 6.17 2.58 2.39 0.02 1.11 11.22 V_Category_NeuNeg_dev:Language_dev 0.26 3.18 0.08 0.93 -5.97 6.49 3.3 Run model comparison for the main effect and interactions First of all, I created reduced models (mod3, mod4, mod5) by removing main effect of valence, language, and interaction from the baseline model, respectively. #Removing main effect of valence from mod mod3 &lt;- update(mod, . ~ . - V_Category_NeuPos_dev - V_Category_NeuNeg_dev) #Removing main effect of language from mod mod4 &lt;- update(mod, . ~ . - Language_dev) #Removing interaction from mod mod5 &lt;- update(mod, . ~ . - V_Category_NeuPos_dev:Language_dev - V_Category_NeuNeg_dev:Language_dev) save(mod3,file=&#39;C:/Users/ibana/OneDrive - University of Glasgow/@Year 3/For Publication/Data and Code/mod3_results.RData&#39;) save(mod4,file=&#39;C:/Users/ibana/OneDrive - University of Glasgow/@Year 3/For Publication/Data and Code/mod4_results.RData&#39;) save(mod5,file=&#39;C:/Users/ibana/OneDrive - University of Glasgow/@Year 3/For Publication/Data and Code/mod5_results.RData&#39;) Then I ran model comparison. Model comparison was conducted with ANOVA. mod_mod3 &lt;- anova(mod, mod3) #baseline model vs reduced wo valence effect mod_mod4 &lt;- anova(mod, mod4) #baseline model vs reduced wo language mod_mod5 &lt;- anova(mod, mod5) #baseline model vs reduced wo val x lang interaction The likelihood ratio test confirmed that the effect of valence was also significant (\\(\\chi^{2}\\)(2) = 6.81, p = .03). kable(mod_mod3) %&gt;% kable_styling npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) mod3 49 335673.2 336079.5 -167787.6 335575.2 NA NA NA mod 51 335670.4 336093.3 -167784.2 335568.4 6.810234 2 0.0332029 The main effect of language is also significant (\\(\\chi^{2}\\)(1) = 25.44, p &lt; .001). kable(mod_mod4) %&gt;% kable_styling npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) mod4 50 335693.8 336108.4 -167796.9 335593.8 NA NA NA mod 51 335670.4 336093.3 -167784.2 335568.4 25.44375 1 5e-07 Valence x language interaction was not statistically significant (\\(\\chi^{2}\\)(2) = 3.40, p = .18). kable(mod_mod5) %&gt;% kable_styling npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) mod5 49 335669.8 336076.1 -167785.9 335571.8 NA NA NA mod 51 335670.4 336093.3 -167784.2 335568.4 3.404829 2 0.182243 3.4 Decompose the significant effects of valence The significant main effect of valence is decomposed with emmeans() function. I used revpairwise to reverse the direction of comparison for easier reporting. Posthoc_V_NeuPos &lt;- emmeans(mod, list(revpairwise ~ V_Category_NeuPos_dev), adjust = &quot;tukey&quot;) Posthoc_V_NeuNeg &lt;- emmeans(mod, list(revpairwise ~ V_Category_NeuNeg_dev), adjust = &quot;tukey&quot;) Here, 0.66 refers to Positive, -0.33 refers to Neutral. Posthoc_V_NeuPos ## $`emmeans of V_Category_NeuPos_dev` ## V_Category_NeuPos_dev emmean SE df asymp.LCL asymp.UCL ## -0.333 230 2.58 Inf 225 235 ## 0.667 224 2.69 Inf 219 229 ## ## Results are averaged over the levels of: V_Category_NeuNeg_dev, Language_dev ## Confidence level used: 0.95 ## ## $`pairwise differences of V_Category_NeuPos_dev` ## 1 estimate SE df z.ratio p.value ## 0.666666666666667 - (-0.333333333333333) -5.44 1.41 Inf -3.852 0.0001 ## ## Results are averaged over the levels of: V_Category_NeuNeg_dev, Language_dev confint(Posthoc_V_NeuPos) ## $`emmeans of V_Category_NeuPos_dev` ## V_Category_NeuPos_dev emmean SE df asymp.LCL asymp.UCL ## -0.333 230 2.58 Inf 225 235 ## 0.667 224 2.69 Inf 219 229 ## ## Results are averaged over the levels of: V_Category_NeuNeg_dev, Language_dev ## Confidence level used: 0.95 ## ## $`pairwise differences of V_Category_NeuPos_dev` ## 1 estimate SE df asymp.LCL asymp.UCL ## 0.666666666666667 - (-0.333333333333333) -5.44 1.41 Inf -8.21 -2.67 ## ## Results are averaged over the levels of: V_Category_NeuNeg_dev, Language_dev ## Confidence level used: 0.95 Thus you can interpret the table as: Value estimate SE df z.ratio p.value asymp.LCL asymp.UCL Positive-Neutral -5.44 1.41 Inf -3.852 0.0001 -8.21 -2.67 Here, 0.66 refers to Negative, -0.33 refers to Neutral. Posthoc_V_NeuNeg ## $`emmeans of V_Category_NeuNeg_dev` ## V_Category_NeuNeg_dev emmean SE df asymp.LCL asymp.UCL ## -0.333 227 2.47 Inf 222 232 ## 0.667 227 2.87 Inf 221 232 ## ## Results are averaged over the levels of: V_Category_NeuPos_dev, Language_dev ## Confidence level used: 0.95 ## ## $`pairwise differences of V_Category_NeuNeg_dev` ## 1 estimate SE df z.ratio p.value ## 0.666666666666667 - (-0.333333333333333) -0.263 1.71 Inf -0.154 0.8780 ## ## Results are averaged over the levels of: V_Category_NeuPos_dev, Language_dev confint(Posthoc_V_NeuNeg) ## $`emmeans of V_Category_NeuNeg_dev` ## V_Category_NeuNeg_dev emmean SE df asymp.LCL asymp.UCL ## -0.333 227 2.47 Inf 222 232 ## 0.667 227 2.87 Inf 221 232 ## ## Results are averaged over the levels of: V_Category_NeuPos_dev, Language_dev ## Confidence level used: 0.95 ## ## $`pairwise differences of V_Category_NeuNeg_dev` ## 1 estimate SE df asymp.LCL asymp.UCL ## 0.666666666666667 - (-0.333333333333333) -0.263 1.71 Inf -3.62 3.1 ## ## Results are averaged over the levels of: V_Category_NeuPos_dev, Language_dev ## Confidence level used: 0.95 Thus you can interpret the table as: Value estimate SE df z.ratio p.value asymp.LCL asymp.UCL Negative-Neutral -0.263 1.71 Inf -0.154 0.8780 -3.62 3.1 3.5 Expolatory analysis: compare positive vs negative ReadingData_ENandNL_PosNeg &lt;- ReadingData_ENandNL %&gt;% select(-V_Category_NeuPos_dev, - V_Category_NeuNeg_dev) %&gt;% mutate(V_Category_PosNeu_dev = if_else(V_Category == &quot;Neutral&quot;, 2/3, -1/3), V_Category_PosNeg_dev = if_else(V_Category == &quot;Negative&quot;, 2/3, -1/3)) mod6 &lt;- glmer(WORD_FIRST_FIXATION_DURATION ~ #Main effects V_Category_PosNeu_dev + V_Category_PosNeg_dev + Language_dev + #Control variables Conc_Mean + WORD_LENGTH + #Interactions V_Category_PosNeu_dev:Language_dev + V_Category_PosNeg_dev:Language_dev + #Random effects (1 + Language_dev + V_Category_PosNeu_dev + V_Category_PosNeg_dev + Conc_Mean + WORD_LENGTH | WORD)+ (1 + Language_dev + V_Category_PosNeu_dev + V_Category_PosNeg_dev + Conc_Mean + WORD_LENGTH | PP_NR), data = ReadingData_ENandNL_PosNeg, family=Gamma(link=&quot;identity&quot;), control = glmerControl(optimizer = &quot;optimx&quot;, calc.derivs = FALSE, optCtrl = list(method = &quot;L-BFGS-B&quot;, maxit = 10000, starttests = FALSE, kkt = FALSE))) save(mod6,file=&#39;C:/Users/ibana/OneDrive - University of Glasgow/@Year 3/For Publication/Data and Code/mod6_results.RData&#39;) The effect of valence is decomposed with emmeans(). Posthoc_V_PosNeg &lt;- emmeans(mod6, list(pairwise ~ V_Category_PosNeg_dev), adjust = &quot;tukey&quot;) Posthoc_V_PosNeg ## $`emmeans of V_Category_PosNeg_dev` ## V_Category_PosNeg_dev emmean SE df asymp.LCL asymp.UCL ## -0.333 227 2.47 Inf 222 232 ## 0.667 232 3.04 Inf 226 238 ## ## Results are averaged over the levels of: V_Category_PosNeu_dev, Language_dev ## Confidence level used: 0.95 ## ## $`pairwise differences of V_Category_PosNeg_dev` ## 1 estimate SE df z.ratio p.value ## (-0.333333333333333) - 0.666666666666667 -5.29 2.01 Inf -2.631 0.0085 ## ## Results are averaged over the levels of: V_Category_PosNeu_dev, Language_dev confint(Posthoc_V_PosNeg) ## $`emmeans of V_Category_PosNeg_dev` ## V_Category_PosNeg_dev emmean SE df asymp.LCL asymp.UCL ## -0.333 227 2.47 Inf 222 232 ## 0.667 232 3.04 Inf 226 238 ## ## Results are averaged over the levels of: V_Category_PosNeu_dev, Language_dev ## Confidence level used: 0.95 ## ## $`pairwise differences of V_Category_PosNeg_dev` ## 1 estimate SE df asymp.LCL asymp.UCL ## (-0.333333333333333) - 0.666666666666667 -5.29 2.01 Inf -9.23 -1.35 ## ## Results are averaged over the levels of: V_Category_PosNeu_dev, Language_dev ## Confidence level used: 0.95 Here -0.33 refers to Positive and 0.66 refers to Negative. Thus you can interpret the table as: Value estimate SE df z.ratio p.value asymp.LCL asymp.UCL Positive-Negative -5.29 2.01 Inf -2.631 0.0085 -9.23 -1.35 3.6 Decompose the non-significant effect of interaction The model comparison did not provide significant results for interaction of Valence x Language, but mod showed V_Category_NeuPos_dev:Language_dev was significant. Decomposing the results here to look into it deeply. Posthoc_Int_NeuPosLang &lt;- emmeans(mod, list(revpairwise ~ V_Category_NeuPos_dev:Language_dev), adjust = &quot;tukey&quot; ) Posthoc_Int_NeuNegLang &lt;- emmeans(mod, list(revpairwise ~ V_Category_NeuNeg_dev:Language_dev), adjust = &quot;tukey&quot; ) Posthoc_Int_PosNegLang &lt;- emmeans(mod6, list(pairwise ~ V_Category_PosNeg_dev:Language_dev), adjust = &quot;tukey&quot; ) The Language_dev -0.5 refers to English, 0.5 refers to English. To decompose the non-significant interaction of valence x language, we only look at the pairwise difference with same languages, which are on the top and bottom rows. Posthoc_Int_NeuPosLang ## $`emmeans of V_Category_NeuPos_dev, Language_dev` ## V_Category_NeuPos_dev Language_dev emmean SE df asymp.LCL asymp.UCL ## -0.333 -0.5 246 3.04 Inf 240 252 ## 0.667 -0.5 237 3.17 Inf 231 244 ## -0.333 0.5 213 2.62 Inf 208 218 ## 0.667 0.5 211 3.10 Inf 205 217 ## ## Results are averaged over the levels of: V_Category_NeuNeg_dev ## Confidence level used: 0.95 ## ## $`pairwise differences of V_Category_NeuPos_dev, Language_dev` ## 1 estimate SE df z.ratio ## (0.666666666666667 -0.5) - (-0.333333333333333 -0.5) -8.52 1.78 Inf -4.778 ## (-0.333333333333333 0.5) - (-0.333333333333333 -0.5) -32.63 2.39 Inf -13.679 ## (-0.333333333333333 0.5) - (0.666666666666667 -0.5) -24.11 2.64 Inf -9.120 ## 0.666666666666667 0.5 - (-0.333333333333333 -0.5) -34.99 3.12 Inf -11.225 ## 0.666666666666667 0.5 - (0.666666666666667 -0.5) -26.47 3.22 Inf -8.226 ## 0.666666666666667 0.5 - (-0.333333333333333 0.5) -2.36 2.03 Inf -1.159 ## p.value ## &lt;.0001 ## &lt;.0001 ## &lt;.0001 ## &lt;.0001 ## &lt;.0001 ## 0.6526 ## ## Results are averaged over the levels of: V_Category_NeuNeg_dev ## P value adjustment: tukey method for comparing a family of 4 estimates confint(Posthoc_Int_NeuPosLang) ## $`emmeans of V_Category_NeuPos_dev, Language_dev` ## V_Category_NeuPos_dev Language_dev emmean SE df asymp.LCL asymp.UCL ## -0.333 -0.5 246 3.04 Inf 240 252 ## 0.667 -0.5 237 3.17 Inf 231 244 ## -0.333 0.5 213 2.62 Inf 208 218 ## 0.667 0.5 211 3.10 Inf 205 217 ## ## Results are averaged over the levels of: V_Category_NeuNeg_dev ## Confidence level used: 0.95 ## ## $`pairwise differences of V_Category_NeuPos_dev, Language_dev` ## 1 estimate SE df ## (0.666666666666667 -0.5) - (-0.333333333333333 -0.5) -8.52 1.78 Inf ## (-0.333333333333333 0.5) - (-0.333333333333333 -0.5) -32.63 2.39 Inf ## (-0.333333333333333 0.5) - (0.666666666666667 -0.5) -24.11 2.64 Inf ## 0.666666666666667 0.5 - (-0.333333333333333 -0.5) -34.99 3.12 Inf ## 0.666666666666667 0.5 - (0.666666666666667 -0.5) -26.47 3.22 Inf ## 0.666666666666667 0.5 - (-0.333333333333333 0.5) -2.36 2.03 Inf ## asymp.LCL asymp.UCL ## -13.11 -3.94 ## -38.76 -26.50 ## -30.90 -17.32 ## -43.00 -26.98 ## -34.73 -18.20 ## -7.58 2.87 ## ## Results are averaged over the levels of: V_Category_NeuNeg_dev ## Confidence level used: 0.95 ## Conf-level adjustment: tukey method for comparing a family of 4 estimates In the above table, 0.66 refers to Positive, 0.33 refers to Neutral. As we only focus on the top and bottom rows of the data, we extract these results: Language Interaction estimate SE df z.ratio p.value asymp.LCL asymp.UCL English Positive-Neutral -8.52 1.78 Inf -4.778 &lt;.0001 -13.11 -3.94 Dutch Positive-Neutral -2.36 2.03 Inf -1.159 0.6526 -7.58 2.87 We will do the same for the other two tables. Posthoc_Int_NeuNegLang ## $`emmeans of V_Category_NeuNeg_dev, Language_dev` ## V_Category_NeuNeg_dev Language_dev emmean SE df asymp.LCL asymp.UCL ## -0.333 -0.5 242 2.86 Inf 236 247 ## 0.667 -0.5 241 3.50 Inf 235 248 ## -0.333 0.5 212 2.54 Inf 207 217 ## 0.667 0.5 212 3.27 Inf 206 218 ## ## Results are averaged over the levels of: V_Category_NeuPos_dev ## Confidence level used: 0.95 ## ## $`pairwise differences of V_Category_NeuNeg_dev, Language_dev` ## 1 estimate SE df z.ratio ## (0.666666666666667 -0.5) - (-0.333333333333333 -0.5) -0.393 2.34 Inf -0.168 ## (-0.333333333333333 0.5) - (-0.333333333333333 -0.5) -29.679 2.20 Inf -13.489 ## (-0.333333333333333 0.5) - (0.666666666666667 -0.5) -29.287 3.02 Inf -9.694 ## 0.666666666666667 0.5 - (-0.333333333333333 -0.5) -29.813 3.08 Inf -9.691 ## 0.666666666666667 0.5 - (0.666666666666667 -0.5) -29.420 3.59 Inf -8.184 ## 0.666666666666667 0.5 - (-0.333333333333333 0.5) -0.133 2.33 Inf -0.057 ## p.value ## 0.9983 ## &lt;.0001 ## &lt;.0001 ## &lt;.0001 ## &lt;.0001 ## 0.9999 ## ## Results are averaged over the levels of: V_Category_NeuPos_dev ## P value adjustment: tukey method for comparing a family of 4 estimates confint(Posthoc_Int_NeuNegLang) ## $`emmeans of V_Category_NeuNeg_dev, Language_dev` ## V_Category_NeuNeg_dev Language_dev emmean SE df asymp.LCL asymp.UCL ## -0.333 -0.5 242 2.86 Inf 236 247 ## 0.667 -0.5 241 3.50 Inf 235 248 ## -0.333 0.5 212 2.54 Inf 207 217 ## 0.667 0.5 212 3.27 Inf 206 218 ## ## Results are averaged over the levels of: V_Category_NeuPos_dev ## Confidence level used: 0.95 ## ## $`pairwise differences of V_Category_NeuNeg_dev, Language_dev` ## 1 estimate SE df ## (0.666666666666667 -0.5) - (-0.333333333333333 -0.5) -0.393 2.34 Inf ## (-0.333333333333333 0.5) - (-0.333333333333333 -0.5) -29.679 2.20 Inf ## (-0.333333333333333 0.5) - (0.666666666666667 -0.5) -29.287 3.02 Inf ## 0.666666666666667 0.5 - (-0.333333333333333 -0.5) -29.813 3.08 Inf ## 0.666666666666667 0.5 - (0.666666666666667 -0.5) -29.420 3.59 Inf ## 0.666666666666667 0.5 - (-0.333333333333333 0.5) -0.133 2.33 Inf ## asymp.LCL asymp.UCL ## -6.40 5.62 ## -35.33 -24.03 ## -37.05 -21.53 ## -37.72 -21.91 ## -38.65 -20.19 ## -6.13 5.86 ## ## Results are averaged over the levels of: V_Category_NeuPos_dev ## Confidence level used: 0.95 ## Conf-level adjustment: tukey method for comparing a family of 4 estimates Language Interaction estimate SE df z.ratio p.value asymp.LCL asymp.UCL English Negative-Neutral -0.393 2.34 Inf -0.168 0.9983 -6.40 5.62 Dutch Negative-Neutral -0.133 2.33 Inf -0.057 0.9999 -6.13 5.86 Posthoc_Int_PosNegLang ## $`emmeans of V_Category_PosNeg_dev, Language_dev` ## V_Category_PosNeg_dev Language_dev emmean SE df asymp.LCL asymp.UCL ## -0.333 -0.5 242 2.86 Inf 236 247 ## 0.667 -0.5 250 3.72 Inf 243 257 ## -0.333 0.5 212 2.54 Inf 207 217 ## 0.667 0.5 214 3.33 Inf 208 221 ## ## Results are averaged over the levels of: V_Category_PosNeu_dev ## Confidence level used: 0.95 ## ## $`pairwise differences of V_Category_PosNeg_dev, Language_dev` ## 1 estimate SE df z.ratio ## (-0.333333333333333 -0.5) - (0.666666666666667 -0.5) -8.31 2.63 Inf -3.156 ## (-0.333333333333333 -0.5) - (-0.333333333333333 0.5) 29.66 2.20 Inf 13.489 ## (-0.333333333333333 -0.5) - 0.666666666666667 0.5 27.39 2.98 Inf 9.195 ## (0.666666666666667 -0.5) - (-0.333333333333333 0.5) 37.97 3.26 Inf 11.665 ## (0.666666666666667 -0.5) - 0.666666666666667 0.5 35.70 3.59 Inf 9.950 ## (-0.333333333333333 0.5) - 0.666666666666667 0.5 -2.27 2.74 Inf -0.830 ## p.value ## 0.0087 ## &lt;.0001 ## &lt;.0001 ## &lt;.0001 ## &lt;.0001 ## 0.8403 ## ## Results are averaged over the levels of: V_Category_PosNeu_dev ## P value adjustment: tukey method for comparing a family of 4 estimates confint(Posthoc_Int_PosNegLang) ## $`emmeans of V_Category_PosNeg_dev, Language_dev` ## V_Category_PosNeg_dev Language_dev emmean SE df asymp.LCL asymp.UCL ## -0.333 -0.5 242 2.86 Inf 236 247 ## 0.667 -0.5 250 3.72 Inf 243 257 ## -0.333 0.5 212 2.54 Inf 207 217 ## 0.667 0.5 214 3.33 Inf 208 221 ## ## Results are averaged over the levels of: V_Category_PosNeu_dev ## Confidence level used: 0.95 ## ## $`pairwise differences of V_Category_PosNeg_dev, Language_dev` ## 1 estimate SE df ## (-0.333333333333333 -0.5) - (0.666666666666667 -0.5) -8.31 2.63 Inf ## (-0.333333333333333 -0.5) - (-0.333333333333333 0.5) 29.66 2.20 Inf ## (-0.333333333333333 -0.5) - 0.666666666666667 0.5 27.39 2.98 Inf ## (0.666666666666667 -0.5) - (-0.333333333333333 0.5) 37.97 3.26 Inf ## (0.666666666666667 -0.5) - 0.666666666666667 0.5 35.70 3.59 Inf ## (-0.333333333333333 0.5) - 0.666666666666667 0.5 -2.27 2.74 Inf ## asymp.LCL asymp.UCL ## -15.1 -1.55 ## 24.0 35.31 ## 19.7 35.04 ## 29.6 46.34 ## 26.5 44.92 ## -9.3 4.76 ## ## Results are averaged over the levels of: V_Category_PosNeu_dev ## Confidence level used: 0.95 ## Conf-level adjustment: tukey method for comparing a family of 4 estimates Language Interaction estimate SE df z.ratio p.value asymp.LCL asymp.UCL English Positive-Negative -8.31 2.63 Inf -3.156 0.0087 -15.1 -1.55 Dutch Positive-Negative -2.27 2.74 Inf -0.830 0.8403 -9.3 4.76 "],["visualisation.html", "Chapter 4 Visualisation 4.1 The final reading dataset 4.2 The baseline model (mod) 4.3 emmip: Interaction-style plots for estimated marginal means 4.4 Assumption Checking", " Chapter 4 Visualisation 4.1 The final reading dataset A violin-box plot is created for the final reading dataset for analysis. ggplot(ReadingData_ENandNL, aes(x = V_Category, y = WORD_FIRST_FIXATION_DURATION, fill = V_Category)) + geom_violin(alpha = .6) + geom_boxplot(width = .2, alpha = .6) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, position = position_dodge(.9)) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1, position = position_dodge(.9))+ scale_x_discrete(name = &quot;Valence Category&quot;) + scale_y_continuous(name = &quot;Single Fixation Duration (ms)&quot;) + scale_fill_viridis_d(option = &quot;E&quot;) + facet_wrap(~Language) + theme_bw() + guides(fill = FALSE) 4.2 The baseline model (mod) I created a Blobbogram for Generalised linear mixed-effect model.broom.mixed::tidy() works on LMM to create a model summary. I then added factor to split the data for colours. modelsummary_vis &lt;- broom.mixed::tidy(mod, effects = c(&quot;ran_pars&quot;, &quot;fixed&quot;),scales = NULL, ran_prefix = NULL, conf.int = TRUE, conf.level = 0.95, conf.method = &quot;Wald&quot;) %&gt;% filter(effect ==&quot;fixed&quot;) %&gt;% filter(term!=&quot;(Intercept)&quot;) #Add factor to split the data for colours modelsummary_vis$Type &lt;- as.factor(ifelse(str_detect(modelsummary_vis$term, &quot;:&quot;), &quot;Interaction&quot;, &quot;Main effect&quot;)) Below ggplot() coding was run to generate a Blobbogram. Condition1 refers to Positive vs Neutral; Condition2 refers to Negative vs Neutral. The minimal theme is applied to make it black &amp; white = colourblind friendly. ggplot(modelsummary_vis, aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high, shape = Type)) + geom_pointrange() + ylab(&quot;Estimates with 95% CIs&quot;) + geom_hline(aes(yintercept = 0), linetype = &quot;dashed&quot;) + scale_x_discrete(limits = c(&quot;V_Category_NeuNeg_dev:Language_dev&quot;, &quot;V_Category_NeuPos_dev:Language_dev&quot;, &quot;WORD_LENGTH&quot;, &quot;Conc_Mean&quot;, &quot;Language_dev&quot;, &quot;V_Category_NeuNeg_dev&quot;, &quot;V_Category_NeuPos_dev&quot;), labels = c(&quot;Condition2:Language&quot;, &quot;Condition1:Language&quot;, &quot;Word Length&quot;, &quot;Concreteness&quot;, &quot;Language&quot;, &quot;Condition2&quot;, &quot;Condition1&quot;)) + xlab(&quot;Fixed effect&quot;) + coord_flip() + theme_bw() 4.3 emmip: Interaction-style plots for estimated marginal means plot_dat &lt;- emmip(mod2, Language~V_Category, plotit = FALSE) ggplot(plot_dat, aes(x = xvar, y = yvar, group = tvar, linetype = tvar, shape = tvar)) + geom_point(size = 2) + geom_line() + labs(x = &quot;Valence Category&quot;, y = &quot;Single Fixation Duration (ms)&quot;, linetype = &quot;Language&quot;, shape = &quot;Language&quot;) + theme_bw() 4.4 Assumption Checking Linearity plot(fitted(mod), residuals(mod)) Absence of collinearity Homoskedasticity Again, this can be checked with residual plots. plot(fitted(mod), residuals(mod)) Normality of residuals hist(residuals(mod)) qqnorm(residuals(mod)) Absence of influential data points This assumption is met with visual investigation of violin boxplot. Independence This assumption is met with modeling (fixed effects: Valence cagetory, Language; random effects: Concreteness, Word Length). "],["references.html", "References", " References Brysbaert, M., Stevens, M., De Deyne, S., Voorspoels, W., &amp; Storms, G. (2014). Norms of age of acquisition and concreteness for 30,000 Dutch words. Acta Psychologica, 150, 8084. https://doi.org/10.1016/j.actpsy.2014.04.010 Brysbaert, M., Warriner, A. B., &amp; Kuperman, V. (2014). Concreteness ratings for 40 thousand generally known English word lemmas. Behavior Research Methods, 46(3), 904911. https://doi.org/10.3758/s13428-013-0403-5 Cop, U., Dirix, N., Drieghe, D., &amp; Duyck, W. (2017). Presenting GECO: An eyetracking corpus of monolingual and bilingual sentence reading. Behavior Research Methods, 49(2), 602615. https://doi.org/10.3758/s13428-016-0734-0 Dijkstra, T., Miwa, K., Brummelhuis, B., Sappelli, M., &amp; Baayen, H. (2010). How cross-language similarity and task demands affect cognate recognition. Journal of Memory and Language, 62(3), 284301. https://doi.org/10.1016/j.jml.2009.12.003 Moors, A., De Houwer, J., Hermans, D., Wanmaker, S., Schie, K. van, Van Harmelen, A.-L., De Schryver, M., De Winne, J., &amp; Brysbaert, M. (2013). Norms of valence, arousal, dominance, and age of acquisition for 4,300 Dutch words. Behavior Research Methods, 45(1), 169177. https://doi.org/10.3758/s13428-012-0243-8 Poort, E. D., &amp; Rodd, J. M. (2019). A Database of DutchEnglish Cognates, Interlingual Homographs and Translation Equivalents. Journal of Cognition, 2(1). https://doi.org/10.5334/joc.67 Toivo, W., &amp; Scheepers, C. (2019). Pupillary responses to affective words in bilinguals first versus second language. PLOS ONE, 14(4), e0210450. https://doi.org/10.1371/journal.pone.0210450 Warriner, A. B., Kuperman, V., &amp; Brysbaert, M. (2013). Norms of valence, arousal, and dominance for 13,915 English lemmas. Behavior Research Methods, 45(4), 11911207. https://doi.org/10.3758/s13428-012-0314-x "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
